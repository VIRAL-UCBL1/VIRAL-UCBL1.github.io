
<!doctype html>
<html lang="en" class="no-js">
  <head>
    
      <meta charset="utf-8">
      <meta name="viewport" content="width=device-width,initial-scale=1">
      
      
      
        <link rel="canonical" href="https://viral-ucbl1.github.io/code_docs/VIRAL/">
      
      
        <link rel="prev" href="../main/">
      
      
        <link rel="next" href="../OllamaChat/">
      
      
      <link rel="icon" href="../../assets/images/favicon.png">
      <meta name="generator" content="mkdocs-1.6.1, mkdocs-material-9.5.49">
    
    
      
        <title>VIRAL - VIRAL</title>
      
    
    
      <link rel="stylesheet" href="../../assets/stylesheets/main.6f8fc17f.min.css">
      
        
        <link rel="stylesheet" href="../../assets/stylesheets/palette.06af60db.min.css">
      
      


    
    
      
    
    
      
        
        
        <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
        <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Roboto:300,300i,400,400i,700,700i%7CRoboto+Mono:400,400i,700,700i&display=fallback">
        <style>:root{--md-text-font:"Roboto";--md-code-font:"Roboto Mono"}</style>
      
    
    
      <link rel="stylesheet" href="../../assets/_mkdocstrings.css">
    
    <script>__md_scope=new URL("../..",location),__md_hash=e=>[...e].reduce(((e,_)=>(e<<5)-e+_.charCodeAt(0)),0),__md_get=(e,_=localStorage,t=__md_scope)=>JSON.parse(_.getItem(t.pathname+"."+e)),__md_set=(e,_,t=localStorage,a=__md_scope)=>{try{t.setItem(a.pathname+"."+e,JSON.stringify(_))}catch(e){}}</script>
    
      

    
    
    
  </head>
  
  
    
    
      
    
    
    
    
    <body dir="ltr" data-md-color-scheme="slate" data-md-color-primary="blue-grey" data-md-color-accent="indigo">
  
    
    <input class="md-toggle" data-md-toggle="drawer" type="checkbox" id="__drawer" autocomplete="off">
    <input class="md-toggle" data-md-toggle="search" type="checkbox" id="__search" autocomplete="off">
    <label class="md-overlay" for="__drawer"></label>
    <div data-md-component="skip">
      
        
        <a href="#overview-of-viral" class="md-skip">
          Skip to content
        </a>
      
    </div>
    <div data-md-component="announce">
      
    </div>
    
    
      

<header class="md-header" data-md-component="header">
  <nav class="md-header__inner md-grid" aria-label="Header">
    <a href="../.." title="VIRAL" class="md-header__button md-logo" aria-label="VIRAL" data-md-component="logo">
      
  
  <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M12 8a3 3 0 0 0 3-3 3 3 0 0 0-3-3 3 3 0 0 0-3 3 3 3 0 0 0 3 3m0 3.54C9.64 9.35 6.5 8 3 8v11c3.5 0 6.64 1.35 9 3.54 2.36-2.19 5.5-3.54 9-3.54V8c-3.5 0-6.64 1.35-9 3.54"/></svg>

    </a>
    <label class="md-header__button md-icon" for="__drawer">
      
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M3 6h18v2H3zm0 5h18v2H3zm0 5h18v2H3z"/></svg>
    </label>
    <div class="md-header__title" data-md-component="header-title">
      <div class="md-header__ellipsis">
        <div class="md-header__topic">
          <span class="md-ellipsis">
            VIRAL
          </span>
        </div>
        <div class="md-header__topic" data-md-component="header-topic">
          <span class="md-ellipsis">
            
              VIRAL
            
          </span>
        </div>
      </div>
    </div>
    
      
        <form class="md-header__option" data-md-component="palette">
  
    
    
    
    <input class="md-option" data-md-color-media="" data-md-color-scheme="slate" data-md-color-primary="blue-grey" data-md-color-accent="indigo"  aria-label="Switch to light mode"  type="radio" name="__palette" id="__palette_0">
    
      <label class="md-header__button md-icon" title="Switch to light mode" for="__palette_1" hidden>
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M12 18c-.89 0-1.74-.2-2.5-.55C11.56 16.5 13 14.42 13 12s-1.44-4.5-3.5-5.45C10.26 6.2 11.11 6 12 6a6 6 0 0 1 6 6 6 6 0 0 1-6 6m8-9.31V4h-4.69L12 .69 8.69 4H4v4.69L.69 12 4 15.31V20h4.69L12 23.31 15.31 20H20v-4.69L23.31 12z"/></svg>
      </label>
    
  
    
    
    
    <input class="md-option" data-md-color-media="" data-md-color-scheme="default" data-md-color-primary="blue-grey" data-md-color-accent="indigo"  aria-label="Switch to dark mode"  type="radio" name="__palette" id="__palette_1">
    
      <label class="md-header__button md-icon" title="Switch to dark mode" for="__palette_0" hidden>
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M12 8a4 4 0 0 0-4 4 4 4 0 0 0 4 4 4 4 0 0 0 4-4 4 4 0 0 0-4-4m0 10a6 6 0 0 1-6-6 6 6 0 0 1 6-6 6 6 0 0 1 6 6 6 6 0 0 1-6 6m8-9.31V4h-4.69L12 .69 8.69 4H4v4.69L.69 12 4 15.31V20h4.69L12 23.31 15.31 20H20v-4.69L23.31 12z"/></svg>
      </label>
    
  
</form>
      
    
    
      <script>var palette=__md_get("__palette");if(palette&&palette.color){if("(prefers-color-scheme)"===palette.color.media){var media=matchMedia("(prefers-color-scheme: light)"),input=document.querySelector(media.matches?"[data-md-color-media='(prefers-color-scheme: light)']":"[data-md-color-media='(prefers-color-scheme: dark)']");palette.color.media=input.getAttribute("data-md-color-media"),palette.color.scheme=input.getAttribute("data-md-color-scheme"),palette.color.primary=input.getAttribute("data-md-color-primary"),palette.color.accent=input.getAttribute("data-md-color-accent")}for(var[key,value]of Object.entries(palette.color))document.body.setAttribute("data-md-color-"+key,value)}</script>
    
    
    
      <label class="md-header__button md-icon" for="__search">
        
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.52 6.52 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5"/></svg>
      </label>
      <div class="md-search" data-md-component="search" role="dialog">
  <label class="md-search__overlay" for="__search"></label>
  <div class="md-search__inner" role="search">
    <form class="md-search__form" name="search">
      <input type="text" class="md-search__input" name="query" aria-label="Search" placeholder="Search" autocapitalize="off" autocorrect="off" autocomplete="off" spellcheck="false" data-md-component="search-query" required>
      <label class="md-search__icon md-icon" for="__search">
        
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.52 6.52 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5"/></svg>
        
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M20 11v2H8l5.5 5.5-1.42 1.42L4.16 12l7.92-7.92L13.5 5.5 8 11z"/></svg>
      </label>
      <nav class="md-search__options" aria-label="Search">
        
          <a href="javascript:void(0)" class="md-search__icon md-icon" title="Share" aria-label="Share" data-clipboard data-clipboard-text="" data-md-component="search-share" tabindex="-1">
            
            <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M18 16.08c-.76 0-1.44.3-1.96.77L8.91 12.7c.05-.23.09-.46.09-.7s-.04-.47-.09-.7l7.05-4.11c.54.5 1.25.81 2.04.81a3 3 0 0 0 3-3 3 3 0 0 0-3-3 3 3 0 0 0-3 3c0 .24.04.47.09.7L8.04 9.81C7.5 9.31 6.79 9 6 9a3 3 0 0 0-3 3 3 3 0 0 0 3 3c.79 0 1.5-.31 2.04-.81l7.12 4.15c-.05.21-.08.43-.08.66 0 1.61 1.31 2.91 2.92 2.91s2.92-1.3 2.92-2.91A2.92 2.92 0 0 0 18 16.08"/></svg>
          </a>
        
        <button type="reset" class="md-search__icon md-icon" title="Clear" aria-label="Clear" tabindex="-1">
          
          <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M19 6.41 17.59 5 12 10.59 6.41 5 5 6.41 10.59 12 5 17.59 6.41 19 12 13.41 17.59 19 19 17.59 13.41 12z"/></svg>
        </button>
      </nav>
      
        <div class="md-search__suggest" data-md-component="search-suggest"></div>
      
    </form>
    <div class="md-search__output">
      <div class="md-search__scrollwrap" tabindex="0" data-md-scrollfix>
        <div class="md-search-result" data-md-component="search-result">
          <div class="md-search-result__meta">
            Initializing search
          </div>
          <ol class="md-search-result__list" role="presentation"></ol>
        </div>
      </div>
    </div>
  </div>
</div>
    
    
      <div class="md-header__source">
        <a href="https://github.com/VIRAL-UCBL1/VIRAL" title="Go to repository" class="md-source" data-md-component="source">
  <div class="md-source__icon md-icon">
    
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 496 512"><!--! Font Awesome Free 6.7.1 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2024 Fonticons, Inc.--><path d="M165.9 397.4c0 2-2.3 3.6-5.2 3.6-3.3.3-5.6-1.3-5.6-3.6 0-2 2.3-3.6 5.2-3.6 3-.3 5.6 1.3 5.6 3.6m-31.1-4.5c-.7 2 1.3 4.3 4.3 4.9 2.6 1 5.6 0 6.2-2s-1.3-4.3-4.3-5.2c-2.6-.7-5.5.3-6.2 2.3m44.2-1.7c-2.9.7-4.9 2.6-4.6 4.9.3 2 2.9 3.3 5.9 2.6 2.9-.7 4.9-2.6 4.6-4.6-.3-1.9-3-3.2-5.9-2.9M244.8 8C106.1 8 0 113.3 0 252c0 110.9 69.8 205.8 169.5 239.2 12.8 2.3 17.3-5.6 17.3-12.1 0-6.2-.3-40.4-.3-61.4 0 0-70 15-84.7-29.8 0 0-11.4-29.1-27.8-36.6 0 0-22.9-15.7 1.6-15.4 0 0 24.9 2 38.6 25.8 21.9 38.6 58.6 27.5 72.9 20.9 2.3-16 8.8-27.1 16-33.7-55.9-6.2-112.3-14.3-112.3-110.5 0-27.5 7.6-41.3 23.6-58.9-2.6-6.5-11.1-33.3 2.6-67.9 20.9-6.5 69 27 69 27 20-5.6 41.5-8.5 62.8-8.5s42.8 2.9 62.8 8.5c0 0 48.1-33.6 69-27 13.7 34.7 5.2 61.4 2.6 67.9 16 17.7 25.8 31.5 25.8 58.9 0 96.5-58.9 104.2-114.8 110.5 9.2 7.9 17 22.9 17 46.4 0 33.7-.3 75.4-.3 83.6 0 6.5 4.6 14.4 17.3 12.1C428.2 457.8 496 362.9 496 252 496 113.3 383.5 8 244.8 8M97.2 352.9c-1.3 1-1 3.3.7 5.2 1.6 1.6 3.9 2.3 5.2 1 1.3-1 1-3.3-.7-5.2-1.6-1.6-3.9-2.3-5.2-1m-10.8-8.1c-.7 1.3.3 2.9 2.3 3.9 1.6 1 3.6.7 4.3-.7.7-1.3-.3-2.9-2.3-3.9-2-.6-3.6-.3-4.3.7m32.4 35.6c-1.6 1.3-1 4.3 1.3 6.2 2.3 2.3 5.2 2.6 6.5 1 1.3-1.3.7-4.3-1.3-6.2-2.2-2.3-5.2-2.6-6.5-1m-11.4-14.7c-1.6 1-1.6 3.6 0 5.9s4.3 3.3 5.6 2.3c1.6-1.3 1.6-3.9 0-6.2-1.4-2.3-4-3.3-5.6-2"/></svg>
  </div>
  <div class="md-source__repository">
    VIRAL-UCBL1/VIRAL
  </div>
</a>
      </div>
    
  </nav>
  
</header>
    
    <div class="md-container" data-md-component="container">
      
      
        
          
            
<nav class="md-tabs" aria-label="Tabs" data-md-component="tabs">
  <div class="md-grid">
    <ul class="md-tabs__list">
      
        
  
  
  
    <li class="md-tabs__item">
      <a href="../.." class="md-tabs__link">
        
  
    
  
  Home

      </a>
    </li>
  

      
        
  
  
  
    <li class="md-tabs__item">
      <a href="../../setup/" class="md-tabs__link">
        
  
    
  
  Setup

      </a>
    </li>
  

      
        
  
  
    
  
  
    
    
      <li class="md-tabs__item md-tabs__item--active">
        <a href="../main/" class="md-tabs__link">
          
  
  Documentation

        </a>
      </li>
    
  

      
    </ul>
  </div>
</nav>
          
        
      
      <main class="md-main" data-md-component="main">
        <div class="md-main__inner md-grid">
          
            
              
              <div class="md-sidebar md-sidebar--primary" data-md-component="sidebar" data-md-type="navigation" >
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    


  


<nav class="md-nav md-nav--primary md-nav--lifted" aria-label="Navigation" data-md-level="0">
  <label class="md-nav__title" for="__drawer">
    <a href="../.." title="VIRAL" class="md-nav__button md-logo" aria-label="VIRAL" data-md-component="logo">
      
  
  <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M12 8a3 3 0 0 0 3-3 3 3 0 0 0-3-3 3 3 0 0 0-3 3 3 3 0 0 0 3 3m0 3.54C9.64 9.35 6.5 8 3 8v11c3.5 0 6.64 1.35 9 3.54 2.36-2.19 5.5-3.54 9-3.54V8c-3.5 0-6.64 1.35-9 3.54"/></svg>

    </a>
    VIRAL
  </label>
  
    <div class="md-nav__source">
      <a href="https://github.com/VIRAL-UCBL1/VIRAL" title="Go to repository" class="md-source" data-md-component="source">
  <div class="md-source__icon md-icon">
    
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 496 512"><!--! Font Awesome Free 6.7.1 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2024 Fonticons, Inc.--><path d="M165.9 397.4c0 2-2.3 3.6-5.2 3.6-3.3.3-5.6-1.3-5.6-3.6 0-2 2.3-3.6 5.2-3.6 3-.3 5.6 1.3 5.6 3.6m-31.1-4.5c-.7 2 1.3 4.3 4.3 4.9 2.6 1 5.6 0 6.2-2s-1.3-4.3-4.3-5.2c-2.6-.7-5.5.3-6.2 2.3m44.2-1.7c-2.9.7-4.9 2.6-4.6 4.9.3 2 2.9 3.3 5.9 2.6 2.9-.7 4.9-2.6 4.6-4.6-.3-1.9-3-3.2-5.9-2.9M244.8 8C106.1 8 0 113.3 0 252c0 110.9 69.8 205.8 169.5 239.2 12.8 2.3 17.3-5.6 17.3-12.1 0-6.2-.3-40.4-.3-61.4 0 0-70 15-84.7-29.8 0 0-11.4-29.1-27.8-36.6 0 0-22.9-15.7 1.6-15.4 0 0 24.9 2 38.6 25.8 21.9 38.6 58.6 27.5 72.9 20.9 2.3-16 8.8-27.1 16-33.7-55.9-6.2-112.3-14.3-112.3-110.5 0-27.5 7.6-41.3 23.6-58.9-2.6-6.5-11.1-33.3 2.6-67.9 20.9-6.5 69 27 69 27 20-5.6 41.5-8.5 62.8-8.5s42.8 2.9 62.8 8.5c0 0 48.1-33.6 69-27 13.7 34.7 5.2 61.4 2.6 67.9 16 17.7 25.8 31.5 25.8 58.9 0 96.5-58.9 104.2-114.8 110.5 9.2 7.9 17 22.9 17 46.4 0 33.7-.3 75.4-.3 83.6 0 6.5 4.6 14.4 17.3 12.1C428.2 457.8 496 362.9 496 252 496 113.3 383.5 8 244.8 8M97.2 352.9c-1.3 1-1 3.3.7 5.2 1.6 1.6 3.9 2.3 5.2 1 1.3-1 1-3.3-.7-5.2-1.6-1.6-3.9-2.3-5.2-1m-10.8-8.1c-.7 1.3.3 2.9 2.3 3.9 1.6 1 3.6.7 4.3-.7.7-1.3-.3-2.9-2.3-3.9-2-.6-3.6-.3-4.3.7m32.4 35.6c-1.6 1.3-1 4.3 1.3 6.2 2.3 2.3 5.2 2.6 6.5 1 1.3-1.3.7-4.3-1.3-6.2-2.2-2.3-5.2-2.6-6.5-1m-11.4-14.7c-1.6 1-1.6 3.6 0 5.9s4.3 3.3 5.6 2.3c1.6-1.3 1.6-3.9 0-6.2-1.4-2.3-4-3.3-5.6-2"/></svg>
  </div>
  <div class="md-source__repository">
    VIRAL-UCBL1/VIRAL
  </div>
</a>
    </div>
  
  <ul class="md-nav__list" data-md-scrollfix>
    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href="../.." class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Home
  </span>
  

      </a>
    </li>
  

    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href="../../setup/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Setup
  </span>
  

      </a>
    </li>
  

    
      
      
  
  
    
  
  
  
    
    
    
      
        
        
      
      
        
      
    
    
    <li class="md-nav__item md-nav__item--active md-nav__item--section md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_3" checked>
        
          
          <label class="md-nav__link" for="__nav_3" id="__nav_3_label" tabindex="">
            
  
  <span class="md-ellipsis">
    Documentation
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="1" aria-labelledby="__nav_3_label" aria-expanded="true">
          <label class="md-nav__title" for="__nav_3">
            <span class="md-nav__icon md-icon"></span>
            Documentation
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../main/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Main
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
    
  
  
  
    <li class="md-nav__item md-nav__item--active">
      
      <input class="md-nav__toggle md-toggle" type="checkbox" id="__toc">
      
      
        
      
      
        <label class="md-nav__link md-nav__link--active" for="__toc">
          
  
  <span class="md-ellipsis">
    VIRAL
  </span>
  

          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <a href="./" class="md-nav__link md-nav__link--active">
        
  
  <span class="md-ellipsis">
    VIRAL
  </span>
  

      </a>
      
        

<nav class="md-nav md-nav--secondary" aria-label="Table of contents">
  
  
  
    
  
  
    <label class="md-nav__title" for="__toc">
      <span class="md-nav__icon md-icon"></span>
      Table of contents
    </label>
    <ul class="md-nav__list" data-md-component="toc" data-md-scrollfix>
      
        <li class="md-nav__item">
  <a href="#src.VIRAL" class="md-nav__link">
    <span class="md-ellipsis">
      VIRAL
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#src.VIRAL.VIRAL" class="md-nav__link">
    <span class="md-ellipsis">
      VIRAL
    </span>
  </a>
  
    <nav class="md-nav" aria-label="VIRAL">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#src.VIRAL.VIRAL.__init__" class="md-nav__link">
    <span class="md-ellipsis">
      __init__
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#src.VIRAL.VIRAL.compile_reward_function" class="md-nav__link">
    <span class="md-ellipsis">
      compile_reward_function
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#src.VIRAL.VIRAL.evaluate_policy" class="md-nav__link">
    <span class="md-ellipsis">
      evaluate_policy
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#src.VIRAL.VIRAL.generate_reward_function" class="md-nav__link">
    <span class="md-ellipsis">
      generate_reward_function
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#src.VIRAL.VIRAL.get_code" class="md-nav__link">
    <span class="md-ellipsis">
      get_code
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#src.VIRAL.VIRAL.get_runnable_function" class="md-nav__link">
    <span class="md-ellipsis">
      get_runnable_function
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#src.VIRAL.VIRAL.self_refine_reward" class="md-nav__link">
    <span class="md-ellipsis">
      self_refine_reward
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#src.VIRAL.VIRAL.test_reward_function" class="md-nav__link">
    <span class="md-ellipsis">
      test_reward_function
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
    </ul>
  
</nav>
      
    </li>
  

              
            
              
                
  
  
  
  
    
    
    
      
      
        
          
          
        
      
    
    
    <li class="md-nav__item md-nav__item--section md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_3_3" >
        
          
          <label class="md-nav__link" for="__nav_3_3" id="__nav_3_3_label" tabindex="">
            
  
  <span class="md-ellipsis">
    Utils
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="2" aria-labelledby="__nav_3_3_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_3_3">
            <span class="md-nav__icon md-icon"></span>
            Utils
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../OllamaChat/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    OllamaChat
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../State/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    State
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../utils/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Utils
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../ObjectivesMetrics/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    ObjectivesMetrics
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
              
                
  
  
  
  
    
    
    
      
      
        
          
          
        
      
    
    
    <li class="md-nav__item md-nav__item--section md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_3_4" >
        
          
          <label class="md-nav__link" for="__nav_3_4" id="__nav_3_4_label" tabindex="">
            
  
  <span class="md-ellipsis">
    RL Algo
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="2" aria-labelledby="__nav_3_4_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_3_4">
            <span class="md-nav__icon md-icon"></span>
            RL Algo
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../RLAlgo/DirectSearch/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    DirectSearch
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../RLAlgo/PPO/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    PPO
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../RLAlgo/Reinforce/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Reinforce
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

    
  </ul>
</nav>
                  </div>
                </div>
              </div>
            
            
              
              <div class="md-sidebar md-sidebar--secondary" data-md-component="sidebar" data-md-type="toc" >
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    

<nav class="md-nav md-nav--secondary" aria-label="Table of contents">
  
  
  
    
  
  
    <label class="md-nav__title" for="__toc">
      <span class="md-nav__icon md-icon"></span>
      Table of contents
    </label>
    <ul class="md-nav__list" data-md-component="toc" data-md-scrollfix>
      
        <li class="md-nav__item">
  <a href="#src.VIRAL" class="md-nav__link">
    <span class="md-ellipsis">
      VIRAL
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#src.VIRAL.VIRAL" class="md-nav__link">
    <span class="md-ellipsis">
      VIRAL
    </span>
  </a>
  
    <nav class="md-nav" aria-label="VIRAL">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#src.VIRAL.VIRAL.__init__" class="md-nav__link">
    <span class="md-ellipsis">
      __init__
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#src.VIRAL.VIRAL.compile_reward_function" class="md-nav__link">
    <span class="md-ellipsis">
      compile_reward_function
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#src.VIRAL.VIRAL.evaluate_policy" class="md-nav__link">
    <span class="md-ellipsis">
      evaluate_policy
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#src.VIRAL.VIRAL.generate_reward_function" class="md-nav__link">
    <span class="md-ellipsis">
      generate_reward_function
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#src.VIRAL.VIRAL.get_code" class="md-nav__link">
    <span class="md-ellipsis">
      get_code
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#src.VIRAL.VIRAL.get_runnable_function" class="md-nav__link">
    <span class="md-ellipsis">
      get_runnable_function
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#src.VIRAL.VIRAL.self_refine_reward" class="md-nav__link">
    <span class="md-ellipsis">
      self_refine_reward
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#src.VIRAL.VIRAL.test_reward_function" class="md-nav__link">
    <span class="md-ellipsis">
      test_reward_function
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
    </ul>
  
</nav>
                  </div>
                </div>
              </div>
            
          
          
            <div class="md-content" data-md-component="content">
              <article class="md-content__inner md-typeset">
                
                  

  
    <a href="https://github.com/VIRAL-UCBL1/VIRAL/edit/main/docs/code_docs/VIRAL.md" title="Edit this page" class="md-content__button md-icon">
      
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M10 20H6V4h7v5h5v3.1l2-2V8l-6-6H6c-1.1 0-2 .9-2 2v16c0 1.1.9 2 2 2h4zm10.2-7c.1 0 .3.1.4.2l1.3 1.3c.2.2.2.6 0 .8l-1 1-2.1-2.1 1-1c.1-.1.2-.2.4-.2m0 3.9L14.1 23H12v-2.1l6.1-6.1z"/></svg>
    </a>
  
  
    
      
    
    <a href="https://github.com/VIRAL-UCBL1/VIRAL/raw/main/docs/code_docs/VIRAL.md" title="View source of this page" class="md-content__button md-icon">
      
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M17 18c.56 0 1 .44 1 1s-.44 1-1 1-1-.44-1-1 .44-1 1-1m0-3c-2.73 0-5.06 1.66-6 4 .94 2.34 3.27 4 6 4s5.06-1.66 6-4c-.94-2.34-3.27-4-6-4m0 6.5a2.5 2.5 0 0 1-2.5-2.5 2.5 2.5 0 0 1 2.5-2.5 2.5 2.5 0 0 1 2.5 2.5 2.5 2.5 0 0 1-2.5 2.5M9.27 20H6V4h7v5h5v4.07c.7.08 1.36.25 2 .49V8l-6-6H6a2 2 0 0 0-2 2v16a2 2 0 0 0 2 2h4.5a8.2 8.2 0 0 1-1.23-2"/></svg>
    </a>
  


<h1 id="overview-of-viral">Overview of VIRAL</h1>


<div class="doc doc-object doc-module">



<a id="src.VIRAL"></a>
    <div class="doc doc-contents first">








  <div class="doc doc-children">








<div class="doc doc-object doc-class">



<h2 id="src.VIRAL.VIRAL" class="doc doc-heading">
            <code>VIRAL</code>


</h2>


    <div class="doc doc-contents ">







              <details class="quote">
                <summary>Source code in <code>src/VIRAL.py</code></summary>
                <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal"> 27</span>
<span class="normal"> 28</span>
<span class="normal"> 29</span>
<span class="normal"> 30</span>
<span class="normal"> 31</span>
<span class="normal"> 32</span>
<span class="normal"> 33</span>
<span class="normal"> 34</span>
<span class="normal"> 35</span>
<span class="normal"> 36</span>
<span class="normal"> 37</span>
<span class="normal"> 38</span>
<span class="normal"> 39</span>
<span class="normal"> 40</span>
<span class="normal"> 41</span>
<span class="normal"> 42</span>
<span class="normal"> 43</span>
<span class="normal"> 44</span>
<span class="normal"> 45</span>
<span class="normal"> 46</span>
<span class="normal"> 47</span>
<span class="normal"> 48</span>
<span class="normal"> 49</span>
<span class="normal"> 50</span>
<span class="normal"> 51</span>
<span class="normal"> 52</span>
<span class="normal"> 53</span>
<span class="normal"> 54</span>
<span class="normal"> 55</span>
<span class="normal"> 56</span>
<span class="normal"> 57</span>
<span class="normal"> 58</span>
<span class="normal"> 59</span>
<span class="normal"> 60</span>
<span class="normal"> 61</span>
<span class="normal"> 62</span>
<span class="normal"> 63</span>
<span class="normal"> 64</span>
<span class="normal"> 65</span>
<span class="normal"> 66</span>
<span class="normal"> 67</span>
<span class="normal"> 68</span>
<span class="normal"> 69</span>
<span class="normal"> 70</span>
<span class="normal"> 71</span>
<span class="normal"> 72</span>
<span class="normal"> 73</span>
<span class="normal"> 74</span>
<span class="normal"> 75</span>
<span class="normal"> 76</span>
<span class="normal"> 77</span>
<span class="normal"> 78</span>
<span class="normal"> 79</span>
<span class="normal"> 80</span>
<span class="normal"> 81</span>
<span class="normal"> 82</span>
<span class="normal"> 83</span>
<span class="normal"> 84</span>
<span class="normal"> 85</span>
<span class="normal"> 86</span>
<span class="normal"> 87</span>
<span class="normal"> 88</span>
<span class="normal"> 89</span>
<span class="normal"> 90</span>
<span class="normal"> 91</span>
<span class="normal"> 92</span>
<span class="normal"> 93</span>
<span class="normal"> 94</span>
<span class="normal"> 95</span>
<span class="normal"> 96</span>
<span class="normal"> 97</span>
<span class="normal"> 98</span>
<span class="normal"> 99</span>
<span class="normal">100</span>
<span class="normal">101</span>
<span class="normal">102</span>
<span class="normal">103</span>
<span class="normal">104</span>
<span class="normal">105</span>
<span class="normal">106</span>
<span class="normal">107</span>
<span class="normal">108</span>
<span class="normal">109</span>
<span class="normal">110</span>
<span class="normal">111</span>
<span class="normal">112</span>
<span class="normal">113</span>
<span class="normal">114</span>
<span class="normal">115</span>
<span class="normal">116</span>
<span class="normal">117</span>
<span class="normal">118</span>
<span class="normal">119</span>
<span class="normal">120</span>
<span class="normal">121</span>
<span class="normal">122</span>
<span class="normal">123</span>
<span class="normal">124</span>
<span class="normal">125</span>
<span class="normal">126</span>
<span class="normal">127</span>
<span class="normal">128</span>
<span class="normal">129</span>
<span class="normal">130</span>
<span class="normal">131</span>
<span class="normal">132</span>
<span class="normal">133</span>
<span class="normal">134</span>
<span class="normal">135</span>
<span class="normal">136</span>
<span class="normal">137</span>
<span class="normal">138</span>
<span class="normal">139</span>
<span class="normal">140</span>
<span class="normal">141</span>
<span class="normal">142</span>
<span class="normal">143</span>
<span class="normal">144</span>
<span class="normal">145</span>
<span class="normal">146</span>
<span class="normal">147</span>
<span class="normal">148</span>
<span class="normal">149</span>
<span class="normal">150</span>
<span class="normal">151</span>
<span class="normal">152</span>
<span class="normal">153</span>
<span class="normal">154</span>
<span class="normal">155</span>
<span class="normal">156</span>
<span class="normal">157</span>
<span class="normal">158</span>
<span class="normal">159</span>
<span class="normal">160</span>
<span class="normal">161</span>
<span class="normal">162</span>
<span class="normal">163</span>
<span class="normal">164</span>
<span class="normal">165</span>
<span class="normal">166</span>
<span class="normal">167</span>
<span class="normal">168</span>
<span class="normal">169</span>
<span class="normal">170</span>
<span class="normal">171</span>
<span class="normal">172</span>
<span class="normal">173</span>
<span class="normal">174</span>
<span class="normal">175</span>
<span class="normal">176</span>
<span class="normal">177</span>
<span class="normal">178</span>
<span class="normal">179</span>
<span class="normal">180</span>
<span class="normal">181</span>
<span class="normal">182</span>
<span class="normal">183</span>
<span class="normal">184</span>
<span class="normal">185</span>
<span class="normal">186</span>
<span class="normal">187</span>
<span class="normal">188</span>
<span class="normal">189</span>
<span class="normal">190</span>
<span class="normal">191</span>
<span class="normal">192</span>
<span class="normal">193</span>
<span class="normal">194</span>
<span class="normal">195</span>
<span class="normal">196</span>
<span class="normal">197</span>
<span class="normal">198</span>
<span class="normal">199</span>
<span class="normal">200</span>
<span class="normal">201</span>
<span class="normal">202</span>
<span class="normal">203</span>
<span class="normal">204</span>
<span class="normal">205</span>
<span class="normal">206</span>
<span class="normal">207</span>
<span class="normal">208</span>
<span class="normal">209</span>
<span class="normal">210</span>
<span class="normal">211</span>
<span class="normal">212</span>
<span class="normal">213</span>
<span class="normal">214</span>
<span class="normal">215</span>
<span class="normal">216</span>
<span class="normal">217</span>
<span class="normal">218</span>
<span class="normal">219</span>
<span class="normal">220</span>
<span class="normal">221</span>
<span class="normal">222</span>
<span class="normal">223</span>
<span class="normal">224</span>
<span class="normal">225</span>
<span class="normal">226</span>
<span class="normal">227</span>
<span class="normal">228</span>
<span class="normal">229</span>
<span class="normal">230</span>
<span class="normal">231</span>
<span class="normal">232</span>
<span class="normal">233</span>
<span class="normal">234</span>
<span class="normal">235</span>
<span class="normal">236</span>
<span class="normal">237</span>
<span class="normal">238</span>
<span class="normal">239</span>
<span class="normal">240</span>
<span class="normal">241</span>
<span class="normal">242</span>
<span class="normal">243</span>
<span class="normal">244</span>
<span class="normal">245</span>
<span class="normal">246</span>
<span class="normal">247</span>
<span class="normal">248</span>
<span class="normal">249</span>
<span class="normal">250</span>
<span class="normal">251</span>
<span class="normal">252</span>
<span class="normal">253</span>
<span class="normal">254</span>
<span class="normal">255</span>
<span class="normal">256</span>
<span class="normal">257</span>
<span class="normal">258</span>
<span class="normal">259</span>
<span class="normal">260</span>
<span class="normal">261</span>
<span class="normal">262</span>
<span class="normal">263</span>
<span class="normal">264</span>
<span class="normal">265</span>
<span class="normal">266</span>
<span class="normal">267</span>
<span class="normal">268</span>
<span class="normal">269</span>
<span class="normal">270</span>
<span class="normal">271</span>
<span class="normal">272</span>
<span class="normal">273</span>
<span class="normal">274</span>
<span class="normal">275</span>
<span class="normal">276</span>
<span class="normal">277</span>
<span class="normal">278</span>
<span class="normal">279</span>
<span class="normal">280</span>
<span class="normal">281</span>
<span class="normal">282</span>
<span class="normal">283</span>
<span class="normal">284</span>
<span class="normal">285</span>
<span class="normal">286</span>
<span class="normal">287</span>
<span class="normal">288</span>
<span class="normal">289</span>
<span class="normal">290</span>
<span class="normal">291</span>
<span class="normal">292</span>
<span class="normal">293</span>
<span class="normal">294</span>
<span class="normal">295</span>
<span class="normal">296</span>
<span class="normal">297</span>
<span class="normal">298</span>
<span class="normal">299</span>
<span class="normal">300</span>
<span class="normal">301</span>
<span class="normal">302</span>
<span class="normal">303</span>
<span class="normal">304</span>
<span class="normal">305</span>
<span class="normal">306</span>
<span class="normal">307</span>
<span class="normal">308</span>
<span class="normal">309</span>
<span class="normal">310</span>
<span class="normal">311</span>
<span class="normal">312</span>
<span class="normal">313</span>
<span class="normal">314</span>
<span class="normal">315</span>
<span class="normal">316</span>
<span class="normal">317</span>
<span class="normal">318</span>
<span class="normal">319</span>
<span class="normal">320</span>
<span class="normal">321</span>
<span class="normal">322</span>
<span class="normal">323</span>
<span class="normal">324</span>
<span class="normal">325</span>
<span class="normal">326</span>
<span class="normal">327</span>
<span class="normal">328</span>
<span class="normal">329</span>
<span class="normal">330</span>
<span class="normal">331</span>
<span class="normal">332</span>
<span class="normal">333</span>
<span class="normal">334</span>
<span class="normal">335</span>
<span class="normal">336</span>
<span class="normal">337</span>
<span class="normal">338</span>
<span class="normal">339</span>
<span class="normal">340</span>
<span class="normal">341</span>
<span class="normal">342</span>
<span class="normal">343</span>
<span class="normal">344</span>
<span class="normal">345</span>
<span class="normal">346</span>
<span class="normal">347</span>
<span class="normal">348</span>
<span class="normal">349</span>
<span class="normal">350</span>
<span class="normal">351</span>
<span class="normal">352</span>
<span class="normal">353</span>
<span class="normal">354</span>
<span class="normal">355</span>
<span class="normal">356</span>
<span class="normal">357</span>
<span class="normal">358</span>
<span class="normal">359</span>
<span class="normal">360</span>
<span class="normal">361</span>
<span class="normal">362</span>
<span class="normal">363</span>
<span class="normal">364</span>
<span class="normal">365</span>
<span class="normal">366</span>
<span class="normal">367</span>
<span class="normal">368</span>
<span class="normal">369</span>
<span class="normal">370</span>
<span class="normal">371</span>
<span class="normal">372</span>
<span class="normal">373</span>
<span class="normal">374</span>
<span class="normal">375</span>
<span class="normal">376</span>
<span class="normal">377</span>
<span class="normal">378</span>
<span class="normal">379</span>
<span class="normal">380</span>
<span class="normal">381</span>
<span class="normal">382</span>
<span class="normal">383</span>
<span class="normal">384</span>
<span class="normal">385</span>
<span class="normal">386</span>
<span class="normal">387</span>
<span class="normal">388</span>
<span class="normal">389</span>
<span class="normal">390</span>
<span class="normal">391</span>
<span class="normal">392</span>
<span class="normal">393</span>
<span class="normal">394</span>
<span class="normal">395</span>
<span class="normal">396</span>
<span class="normal">397</span>
<span class="normal">398</span>
<span class="normal">399</span>
<span class="normal">400</span>
<span class="normal">401</span>
<span class="normal">402</span>
<span class="normal">403</span>
<span class="normal">404</span>
<span class="normal">405</span>
<span class="normal">406</span>
<span class="normal">407</span>
<span class="normal">408</span>
<span class="normal">409</span>
<span class="normal">410</span>
<span class="normal">411</span>
<span class="normal">412</span>
<span class="normal">413</span>
<span class="normal">414</span>
<span class="normal">415</span>
<span class="normal">416</span>
<span class="normal">417</span>
<span class="normal">418</span>
<span class="normal">419</span>
<span class="normal">420</span>
<span class="normal">421</span>
<span class="normal">422</span>
<span class="normal">423</span>
<span class="normal">424</span>
<span class="normal">425</span>
<span class="normal">426</span>
<span class="normal">427</span>
<span class="normal">428</span>
<span class="normal">429</span>
<span class="normal">430</span>
<span class="normal">431</span>
<span class="normal">432</span>
<span class="normal">433</span>
<span class="normal">434</span>
<span class="normal">435</span>
<span class="normal">436</span>
<span class="normal">437</span>
<span class="normal">438</span>
<span class="normal">439</span>
<span class="normal">440</span>
<span class="normal">441</span>
<span class="normal">442</span>
<span class="normal">443</span>
<span class="normal">444</span>
<span class="normal">445</span>
<span class="normal">446</span>
<span class="normal">447</span>
<span class="normal">448</span>
<span class="normal">449</span>
<span class="normal">450</span>
<span class="normal">451</span>
<span class="normal">452</span>
<span class="normal">453</span>
<span class="normal">454</span>
<span class="normal">455</span>
<span class="normal">456</span>
<span class="normal">457</span>
<span class="normal">458</span>
<span class="normal">459</span>
<span class="normal">460</span>
<span class="normal">461</span>
<span class="normal">462</span>
<span class="normal">463</span>
<span class="normal">464</span>
<span class="normal">465</span>
<span class="normal">466</span>
<span class="normal">467</span>
<span class="normal">468</span>
<span class="normal">469</span>
<span class="normal">470</span>
<span class="normal">471</span>
<span class="normal">472</span>
<span class="normal">473</span>
<span class="normal">474</span>
<span class="normal">475</span>
<span class="normal">476</span>
<span class="normal">477</span>
<span class="normal">478</span>
<span class="normal">479</span>
<span class="normal">480</span>
<span class="normal">481</span>
<span class="normal">482</span>
<span class="normal">483</span>
<span class="normal">484</span>
<span class="normal">485</span>
<span class="normal">486</span>
<span class="normal">487</span>
<span class="normal">488</span>
<span class="normal">489</span>
<span class="normal">490</span>
<span class="normal">491</span>
<span class="normal">492</span>
<span class="normal">493</span>
<span class="normal">494</span>
<span class="normal">495</span>
<span class="normal">496</span>
<span class="normal">497</span>
<span class="normal">498</span>
<span class="normal">499</span>
<span class="normal">500</span>
<span class="normal">501</span>
<span class="normal">502</span>
<span class="normal">503</span>
<span class="normal">504</span>
<span class="normal">505</span>
<span class="normal">506</span>
<span class="normal">507</span>
<span class="normal">508</span>
<span class="normal">509</span>
<span class="normal">510</span>
<span class="normal">511</span>
<span class="normal">512</span>
<span class="normal">513</span>
<span class="normal">514</span>
<span class="normal">515</span>
<span class="normal">516</span>
<span class="normal">517</span>
<span class="normal">518</span>
<span class="normal">519</span>
<span class="normal">520</span>
<span class="normal">521</span>
<span class="normal">522</span>
<span class="normal">523</span>
<span class="normal">524</span>
<span class="normal">525</span>
<span class="normal">526</span>
<span class="normal">527</span>
<span class="normal">528</span>
<span class="normal">529</span>
<span class="normal">530</span>
<span class="normal">531</span>
<span class="normal">532</span>
<span class="normal">533</span>
<span class="normal">534</span>
<span class="normal">535</span>
<span class="normal">536</span>
<span class="normal">537</span>
<span class="normal">538</span>
<span class="normal">539</span>
<span class="normal">540</span>
<span class="normal">541</span>
<span class="normal">542</span>
<span class="normal">543</span>
<span class="normal">544</span>
<span class="normal">545</span>
<span class="normal">546</span>
<span class="normal">547</span>
<span class="normal">548</span>
<span class="normal">549</span>
<span class="normal">550</span>
<span class="normal">551</span>
<span class="normal">552</span>
<span class="normal">553</span>
<span class="normal">554</span>
<span class="normal">555</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">class</span> <span class="nc">VIRAL</span><span class="p">:</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">learning_algo</span><span class="p">:</span> <span class="n">Algo</span><span class="p">,</span>
        <span class="n">env_type</span> <span class="p">:</span> <span class="n">Environments</span><span class="p">,</span>
        <span class="n">success_function</span><span class="p">:</span> <span class="n">Callable</span><span class="p">,</span>
        <span class="n">objectives_metrics</span><span class="p">:</span> <span class="n">List</span><span class="p">[</span><span class="nb">callable</span><span class="p">]</span> <span class="o">=</span> <span class="p">[],</span>
        <span class="n">model</span><span class="p">:</span> <span class="nb">str</span> <span class="o">=</span> <span class="s2">&quot;qwen2.5-coder&quot;</span><span class="p">,</span>
        <span class="n">options</span><span class="p">:</span> <span class="nb">dict</span> <span class="o">=</span> <span class="p">{},</span>
    <span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Initialize VIRAL architecture for dynamic reward function generation</span>
<span class="sd">            Args:</span>
<span class="sd">                model (str): Language model for reward generation</span>
<span class="sd">                learning_method (str): Reinforcement learning method</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="n">options</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">&quot;seed&quot;</span><span class="p">)</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">options</span><span class="p">[</span><span class="s2">&quot;seed&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">random</span><span class="o">.</span><span class="n">randint</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1000000</span><span class="p">)</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">llm</span> <span class="o">=</span> <span class="n">OllamaChat</span><span class="p">(</span>
            <span class="n">model</span><span class="o">=</span><span class="n">model</span><span class="p">,</span>
            <span class="n">system_prompt</span><span class="o">=</span><span class="s2">&quot;&quot;&quot;</span>
<span class="s2">        You are an expert in Reinforcement Learning specialized in designing reward functions.</span>
<span class="s2">        Strict criteria:</span>
<span class="s2">        - Complete ONLY the reward function code</span>
<span class="s2">        - Use Python format</span>
<span class="s2">        - Give no additional explanations</span>
<span class="s2">        - Focus on the Gymnasium environment </span>
<span class="s2">        - Take into the observation of the state, the terminated and truncated boolean</span>
<span class="s2">        - STOP immediately your completion after the last return</span>
<span class="s2">        &quot;&quot;&quot;</span><span class="p">,</span>
            <span class="n">options</span><span class="o">=</span><span class="n">options</span><span class="p">,</span>
        <span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">env_type</span> <span class="p">:</span> <span class="n">Environments</span> <span class="o">=</span> <span class="n">env_type</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">success_function</span> <span class="o">=</span> <span class="n">success_function</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">env</span> <span class="o">=</span> <span class="kc">None</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">objectives_metrics</span> <span class="o">=</span> <span class="n">objectives_metrics</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">learning_algo</span><span class="p">:</span> <span class="n">Algo</span> <span class="o">=</span> <span class="n">learning_algo</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">learning_method</span> <span class="o">=</span> <span class="kc">None</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">logger</span> <span class="o">=</span> <span class="n">getLogger</span><span class="p">(</span><span class="s2">&quot;VIRAL&quot;</span><span class="p">)</span>
        <span class="c1"># self._learning(self.memory[0])</span>

        <span class="k">if</span> <span class="n">os</span><span class="o">.</span><span class="n">name</span> <span class="o">==</span> <span class="s2">&quot;posix&quot;</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">queue</span> <span class="o">=</span> <span class="n">Queue</span><span class="p">()</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">memory</span><span class="p">:</span> <span class="n">List</span><span class="p">[</span><span class="n">State</span><span class="p">]</span> <span class="o">=</span> <span class="p">[</span><span class="n">State</span><span class="p">(</span><span class="mi">0</span><span class="p">)]</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">multi_process</span><span class="p">:</span> <span class="nb">list</span><span class="p">[</span><span class="n">Process</span><span class="p">]</span> <span class="o">=</span> <span class="p">[]</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">multi_process</span><span class="o">.</span><span class="n">append</span><span class="p">(</span>
                <span class="n">Process</span><span class="p">(</span>
                    <span class="n">target</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">_learning</span><span class="p">,</span>
                    <span class="n">args</span><span class="o">=</span><span class="p">(</span>
                        <span class="bp">self</span><span class="o">.</span><span class="n">memory</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span>
                        <span class="bp">self</span><span class="o">.</span><span class="n">queue</span><span class="p">,</span>
                    <span class="p">),</span>
                <span class="p">)</span>
            <span class="p">)</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">multi_process</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">start</span><span class="p">()</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">to_get</span> <span class="o">=</span> <span class="mi">1</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">memory</span><span class="p">:</span> <span class="n">List</span><span class="p">[</span><span class="n">State</span><span class="p">]</span> <span class="o">=</span> <span class="p">[</span><span class="n">State</span><span class="p">(</span><span class="mi">0</span><span class="p">)]</span>


    <span class="k">def</span> <span class="nf">generate_reward_function</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span> <span class="n">task_description</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span> <span class="n">iterations</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">1</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="n">List</span><span class="p">[</span><span class="n">State</span><span class="p">]:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Generate and iteratively improve a reward function using a Language Model (LLM).</span>

<span class="sd">        This method implements a sophisticated reward function generation process </span>
<span class="sd">        that involves multiple stages of creation, evaluation, and refinement.</span>

<span class="sd">        Key Stages:</span>
<span class="sd">            1. Initial Function Generation: Create two initial reward function candidates</span>
<span class="sd">            2. Evaluation: Compare and identify the best and worst performing functions</span>
<span class="sd">            3. Iterative Refinement: Progressively improve the worst-performing function</span>

<span class="sd">        Args:</span>
<span class="sd">            task_description (str): A detailed description of the task or environment </span>
<span class="sd">                                    for which the reward function is being generated.</span>
<span class="sd">            iterations (int, optional): Number of refinement iterations to perform. </span>
<span class="sd">                                        Defaults to 1.</span>

<span class="sd">        Returns:</span>
<span class="sd">            List[State]: A list of generated and refined reward function states, </span>
<span class="sd">                        containing information about each function&#39;s performance </span>
<span class="sd">                        and implementation.</span>

<span class="sd">        Process Overview:</span>
<span class="sd">            - Generates two initial reward functions using an LLM</span>
<span class="sd">            - Evaluates these functions using a policy evaluation method</span>
<span class="sd">            - Selects the worst-performing function for refinement</span>
<span class="sd">            - Iteratively refines the function through self-refinement</span>
<span class="sd">            - Tracks the evolution of reward functions in the memory</span>

<span class="sd">        Detailed Workflow:</span>
<span class="sd">            1. Generate two initial reward functions</span>
<span class="sd">                - Uses a predefined prompt template</span>
<span class="sd">                - Applies configurable LLM generation options</span>
<span class="sd">                - Compiles and tests each generated function</span>
<span class="sd">            2. Evaluates initial functions</span>
<span class="sd">                - Identifies best and worst performing functions</span>
<span class="sd">            3. Iterative Refinement</span>
<span class="sd">                - Applies self-refinement to the worst-performing function</span>
<span class="sd">                - Re-evaluates after each refinement</span>
<span class="sd">                - Repeats for specified number of iterations</span>

<span class="sd">        Note:</span>
<span class="sd">            - Uses dynamic LLM configuration options</span>
<span class="sd">            - Supports flexible environment types</span>
<span class="sd">            - Provides a systematic approach to reward function generation</span>
<span class="sd">            - Logging at various stages for debugging and tracking</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="c1"># TODO Pourquoi additional_options ici et pas dans le constructeur ?</span>
        <span class="n">additional_options</span> <span class="o">=</span> <span class="p">{</span>
            <span class="s2">&quot;temperature&quot;</span><span class="p">:</span> <span class="mi">1</span><span class="p">,</span>
            <span class="c1"># &quot;num_predict&quot;: 3, # l&#39;impression que a change rien a creuser</span>
            <span class="c1"># &quot;mirostat&quot; : 1,</span>
            <span class="c1"># &quot;mirostat_eta&quot; : 0.01, #gre la vitesse de rponses du model (0.1 par dfaut) plus c&#39;est petit plus c&#39;est lent</span>
            <span class="c1"># &quot;mirostat_tau&quot; : 4.0, #gre la balance entre la diversit et la coherence des rponses (5.0 par dfaut) plus c&#39;est petit plus c&#39;est focus et cohrent</span>
            <span class="c1"># num_ctx&quot;: 2048, # nombre de tokens contextuels (2048 par dfaut peut tre pas ncessaire de changer)</span>
            <span class="c1"># repeat_last_n&quot;: 64, # combien le model regarde en arrire pour viter de rpter les rponses (64 par dfaut large pour nous)</span>
            <span class="c1"># &quot;repeat_penalty&quot;: 1.5, # pnalit pour viter de rpter les rponses (1.1 par dfaut au mac 1.5 intressant a modificer je pense)</span>
            <span class="c1"># &quot;stop&quot;: &quot;stop you here&quot; # pour stopper la gnration de texte pas intressant pour nous</span>
            <span class="c1"># &quot;tfs_z&quot;: 1.2, #reduire l&#39;impacte des token les moins &quot;pertinents&quot; (1.0 par dfaut pour dsactiver 2.0 max)</span>
            <span class="c1"># &quot;top_k&quot;: 30, #reduit la probabilit de gnrer des non-sens (40 par dfaut, 100 pour gnrer des rponses plus diverses, 10 pour des rponses plus &quot;conservatrices&quot;)</span>
            <span class="c1"># &quot;top_p&quot;: 0.95, #marche avec le top_k une forte valeur pour des texte plus diverses (0.9 par dfaut)</span>
            <span class="c1"># &quot;min_p&quot;: 0.05, #alternative au top_p, vise a s&#39;assurer de la balance entre qualit et diversit (0.0 par dfaut)</span>
            <span class="c1"># &quot;seed&quot;: 42, # a utiliser pour la reproductibilit des rsultats (important si publication)</span>
        <span class="p">}</span>
        <span class="c1">### INIT STAGE ###</span>
        <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">]:</span>
            <span class="n">prompt</span> <span class="o">=</span> <span class="sa">f</span><span class="s2">&quot;&quot;&quot;</span>
<span class="s2">        Complete the reward function for a </span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">env_type</span><span class="o">.</span><span class="n">value</span><span class="si">}</span><span class="s2"> environment.</span>
<span class="s2">        Task Description: </span><span class="si">{</span><span class="n">task_description</span><span class="si">}</span><span class="s2"> Iteration </span><span class="si">{</span><span class="n">i</span><span class="o">+</span><span class="mi">1</span><span class="si">}</span><span class="s2">/</span><span class="si">{</span><span class="mi">2</span><span class="si">}</span>

<span class="s2">        complete this sentence:</span>
<span class="s2">        def reward_func(observations:np.ndarray, terminated: bool, truncated: bool) -&gt; float:</span>
<span class="s2">            </span><span class="se">\&quot;\&quot;\&quot;</span><span class="s2">Reward function for </span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">env_type</span><span class="o">.</span><span class="n">value</span><span class="si">}</span>

<span class="s2">            Args:</span>
<span class="s2">                observations (np.ndarray): observation on the current state</span>
<span class="s2">                terminated (bool): episode is terminated due a failure</span>
<span class="s2">                truncated (bool): episode is truncated due a success</span>

<span class="s2">            Returns:</span>
<span class="s2">                float: The reward for the current step</span>
<span class="s2">            </span><span class="se">\&quot;\&quot;\&quot;</span>
<span class="s2">        &quot;&quot;&quot;</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">llm</span><span class="o">.</span><span class="n">add_message</span><span class="p">(</span><span class="n">prompt</span><span class="p">)</span>
            <span class="n">response</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">llm</span><span class="o">.</span><span class="n">generate_response</span><span class="p">(</span>
                <span class="n">stream</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">additional_options</span><span class="o">=</span><span class="n">additional_options</span>
            <span class="p">)</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;additional options: </span><span class="si">{</span><span class="n">additional_options</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
            <span class="n">response</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">llm</span><span class="o">.</span><span class="n">print_Generator_and_return</span><span class="p">(</span><span class="n">response</span><span class="p">,</span> <span class="n">i</span><span class="p">)</span>
            <span class="n">reward_func</span><span class="p">,</span> <span class="n">response</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">get_runnable_function</span><span class="p">(</span><span class="n">response</span><span class="p">)</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">memory</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">State</span><span class="p">(</span><span class="n">i</span><span class="p">,</span> <span class="n">reward_func</span><span class="p">,</span> <span class="n">response</span><span class="p">))</span>

        <span class="n">best_idx</span><span class="p">,</span> <span class="n">worst_idx</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">evaluate_policy</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">logger</span><span class="o">.</span><span class="n">debug</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;state to refine: </span><span class="si">{</span><span class="n">worst_idx</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
        <span class="c1">### SECOND STAGE ###</span>
        <span class="k">for</span> <span class="n">n</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">iterations</span> <span class="o">-</span> <span class="mi">1</span><span class="p">):</span>
            <span class="n">new_idx</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">self_refine_reward</span><span class="p">(</span><span class="n">worst_idx</span><span class="p">)</span>
            <span class="n">best_idx</span><span class="p">,</span> <span class="n">worst_idx</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">evaluate_policy</span><span class="p">(</span><span class="n">best_idx</span><span class="p">,</span> <span class="n">new_idx</span><span class="p">)</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">logger</span><span class="o">.</span><span class="n">debug</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;state to refine: </span><span class="si">{</span><span class="n">worst_idx</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">memory</span>

    <span class="k">def</span> <span class="nf">get_code</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">response</span><span class="p">:</span> <span class="nb">str</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">str</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Clean and validate a code response by removing code block markers and ensuring a function definition.</span>

<span class="sd">        This method is designed to process code responses, typically extracted from text or code blocks,</span>
<span class="sd">        by performing the following operations:\n</span>
<span class="sd">        1. Remove leading and trailing code block markers (```),</span>
<span class="sd">        2. Remove the &#39;python&#39; language identifier,</span>
<span class="sd">        3. Strip any additional whitespace</span>
<span class="sd">        4. Validate that the response contains a function definition</span>

<span class="sd">        Args:</span>
<span class="sd">            response (str): The raw code response to be cleaned and validated.</span>

<span class="sd">        Returns:</span>
<span class="sd">            str: The cleaned code response containing a function definition.</span>

<span class="sd">        Raises:</span>
<span class="sd">            ValueError: If the response does not contain a valid function definition </span>
<span class="sd">                        (i.e., if &quot;def &quot; is not present in the cleaned response).</span>

<span class="sd">        Logging:</span>
<span class="sd">            Logs the cleaned code at DEBUG level for debugging purposes.</span>
<span class="sd">    &quot;&quot;&quot;</span>
        <span class="n">cleaned_response</span> <span class="o">=</span> <span class="n">response</span><span class="o">.</span><span class="n">strip</span><span class="p">(</span><span class="s2">&quot;```&quot;</span><span class="p">)</span><span class="o">.</span><span class="n">replace</span><span class="p">(</span><span class="s2">&quot;python&quot;</span><span class="p">,</span> <span class="s2">&quot;&quot;</span><span class="p">)</span><span class="o">.</span><span class="n">strip</span><span class="p">()</span>
        <span class="k">if</span> <span class="s2">&quot;def &quot;</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">cleaned_response</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;The answer does not contain a valid function definition.&quot;</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">logger</span><span class="o">.</span><span class="n">debug</span><span class="p">(</span><span class="s2">&quot;Code nettoy pour compilation :</span><span class="se">\n</span><span class="s2">&quot;</span> <span class="o">+</span> <span class="n">cleaned_response</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">cleaned_response</span>

    <span class="k">def</span> <span class="nf">get_runnable_function</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">response</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span> <span class="n">error</span><span class="p">:</span> <span class="nb">str</span> <span class="o">=</span> <span class="kc">None</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Callable</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Process and validate a reward function for a gym environment.</span>

<span class="sd">        This method attempts to generate and validate a reward function by:\n</span>
<span class="sd">        1. Handling potential previous errors</span>
<span class="sd">        2. Creating a gym environment</span>
<span class="sd">        3. Cleaning and compiling the code</span>
<span class="sd">        4. Testing the reward function with a sample action</span>
<span class="sd">        5. Recursively handling various potential errors</span>

<span class="sd">        Args:</span>
<span class="sd">            response (str): The code response containing the reward function definition.</span>
<span class="sd">            error (str, optional): Previous error message to be added to LLM context. </span>
<span class="sd">                                    Defaults to None.</span>

<span class="sd">        Returns:</span>
<span class="sd">            tuple: A tuple containing:</span>
<span class="sd">                - Callable: The compiled and validated reward function</span>
<span class="sd">                - str: The original response code</span>

<span class="sd">        Raises:</span>
<span class="sd">            - ValueError: Invalid function definition</span>
<span class="sd">            - SyntaxError: Syntax issues in the function</span>
<span class="sd">            - RuntimeError: Execution problems during function testing</span>

<span class="sd">        Note:</span>
<span class="sd">            - Uses recursion to handle potential errors</span>
<span class="sd">            - Relies on get_code, compile_reward_function, and test_reward_function methods</span>
<span class="sd">            - Provides a robust mechanism for generating valid reward functions</span>
<span class="sd">    &quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="n">error</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">llm</span><span class="o">.</span><span class="n">add_message</span><span class="p">(</span><span class="n">error</span><span class="p">)</span>
            <span class="n">response</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">llm</span><span class="o">.</span><span class="n">generate_response</span><span class="p">(</span><span class="n">stream</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
            <span class="n">response</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">llm</span><span class="o">.</span><span class="n">print_Generator_and_return</span><span class="p">(</span><span class="n">response</span><span class="p">)</span>
        <span class="k">try</span><span class="p">:</span>
            <span class="n">env</span> <span class="o">=</span> <span class="n">gym</span><span class="o">.</span><span class="n">make</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">env_type</span><span class="o">.</span><span class="n">value</span><span class="p">)</span>
            <span class="n">response</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">get_code</span><span class="p">(</span><span class="n">response</span><span class="p">)</span>
            <span class="n">reward_func</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">compile_reward_function</span><span class="p">(</span><span class="n">response</span><span class="p">)</span>
            <span class="n">state</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="n">env</span><span class="o">.</span><span class="n">reset</span><span class="p">()</span>
            <span class="n">action</span> <span class="o">=</span> <span class="n">env</span><span class="o">.</span><span class="n">action_space</span><span class="o">.</span><span class="n">sample</span><span class="p">()</span>
            <span class="n">next_observation</span><span class="p">,</span> <span class="n">_</span><span class="p">,</span> <span class="n">terminated</span><span class="p">,</span> <span class="n">truncated</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="n">env</span><span class="o">.</span><span class="n">step</span><span class="p">(</span><span class="n">action</span><span class="p">)</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">test_reward_function</span><span class="p">(</span>
                <span class="n">reward_func</span><span class="p">,</span>
                <span class="n">observations</span><span class="o">=</span><span class="n">next_observation</span><span class="p">,</span>
                <span class="n">terminated</span><span class="o">=</span><span class="n">terminated</span><span class="p">,</span>
                <span class="n">truncated</span><span class="o">=</span><span class="n">truncated</span><span class="p">,</span>
            <span class="p">)</span>
        <span class="k">except</span> <span class="ne">ValueError</span> <span class="k">as</span> <span class="n">e</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">logger</span><span class="o">.</span><span class="n">warning</span><span class="p">(</span><span class="nb">str</span><span class="p">(</span><span class="n">e</span><span class="p">))</span>
            <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">get_runnable_function</span><span class="p">(</span><span class="n">response</span><span class="p">,</span> <span class="nb">str</span><span class="p">(</span><span class="n">e</span><span class="p">))</span>
        <span class="k">except</span> <span class="ne">SyntaxError</span> <span class="k">as</span> <span class="n">e</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">logger</span><span class="o">.</span><span class="n">warning</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Error syntax </span><span class="si">{</span><span class="n">e</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
            <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">get_runnable_function</span><span class="p">(</span><span class="n">response</span><span class="p">,</span> <span class="nb">str</span><span class="p">(</span><span class="n">e</span><span class="p">))</span>
        <span class="k">except</span> <span class="ne">RuntimeError</span> <span class="k">as</span> <span class="n">e</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">logger</span><span class="o">.</span><span class="n">warning</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Error execution </span><span class="si">{</span><span class="n">e</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
            <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">get_runnable_function</span><span class="p">(</span><span class="n">response</span><span class="p">,</span> <span class="nb">str</span><span class="p">(</span><span class="n">e</span><span class="p">))</span>

        <span class="k">return</span> <span class="n">reward_func</span><span class="p">,</span> <span class="n">response</span>

    <span class="k">def</span> <span class="nf">compile_reward_function</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">response</span><span class="p">:</span> <span class="nb">str</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Callable</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Compile a reward function dynamically from a string response.</span>

<span class="sd">        This method takes a code string representing a reward function and dynamically </span>
<span class="sd">        compiles it into an executable Python function. It provides a secure way to </span>
<span class="sd">        generate reward functions for reinforcement learning environments.</span>

<span class="sd">        Key Features:</span>
<span class="sd">            - Dynamically executes code in an isolated global namespace</span>
<span class="sd">            - Provides access to NumPy functions</span>
<span class="sd">            - Extracts the compiled function by its name</span>
<span class="sd">            - Robust error handling for syntax issues</span>

<span class="sd">        Args:</span>
<span class="sd">            response (str): A string containing a complete Python function definition </span>
<span class="sd">                            for a reward function.</span>

<span class="sd">        Returns:</span>
<span class="sd">            Callable: The compiled reward function that can be called with appropriate </span>
<span class="sd">                    arguments in a gym environment.</span>

<span class="sd">        Raises:</span>
<span class="sd">            SyntaxError: If the provided code contains invalid Python syntax.</span>
<span class="sd">            ValueError: If the function cannot be extracted from the compiled namespace.</span>

<span class="sd">        Notes:</span>
<span class="sd">            - Uses `exec()` for dynamic code compilation</span>
<span class="sd">            - Provides NumPy (`np`) in the execution namespace</span>
<span class="sd">            - Assumes the last function defined in the response is the reward function</span>
<span class="sd">    &quot;&quot;&quot;</span>

        <span class="n">exec_globals</span> <span class="o">=</span> <span class="p">{}</span>
        <span class="n">exec_globals</span><span class="p">[</span><span class="s2">&quot;np&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">np</span>
        <span class="k">try</span><span class="p">:</span>
            <span class="n">exec</span><span class="p">(</span><span class="n">response</span><span class="p">,</span> <span class="n">exec_globals</span><span class="p">)</span>
        <span class="k">except</span> <span class="ne">SyntaxError</span> <span class="k">as</span> <span class="n">e</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">SyntaxError</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Syntax error in the generated code : </span><span class="si">{</span><span class="n">e</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>

        <span class="n">reward_function_name</span> <span class="o">=</span> <span class="n">response</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="s2">&quot;(&quot;</span><span class="p">)[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">split</span><span class="p">()[</span>
            <span class="o">-</span><span class="mi">1</span>
        <span class="p">]</span>  <span class="c1"># rcup le nom de la fonction</span>
        <span class="n">reward_function</span> <span class="o">=</span> <span class="n">exec_globals</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="n">reward_function_name</span><span class="p">)</span>

        <span class="k">return</span> <span class="n">reward_function</span>

    <span class="k">def</span> <span class="nf">test_reward_function</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">reward_function</span><span class="p">:</span> <span class="n">Callable</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Test the compiled reward function with provided inputs to validate its execution.</span>

<span class="sd">        This method serves as a crucial validation step in the reward function generation </span>
<span class="sd">        process. It attempts to execute the reward function with the given arguments and </span>
<span class="sd">        logs the output or raises an error if execution fails.</span>

<span class="sd">        Purpose:</span>
<span class="sd">            - Verify the reward function can be executed without errors</span>
<span class="sd">            - Log the reward function&#39;s output for debugging</span>
<span class="sd">            - Ensure the function returns a valid result in the context of a gym environment</span>

<span class="sd">        Args:</span>
<span class="sd">            reward_function (Callable): The compiled reward function to be tested.</span>
<span class="sd">            *args: Variable length argument list to pass to the reward function.</span>
<span class="sd">                Typically includes observations, actions, or environment states.</span>
<span class="sd">            **kwargs: Arbitrary keyword arguments to pass to the reward function.</span>
<span class="sd">                May include additional context like &#39;terminated&#39; or &#39;truncated&#39; flags.</span>

<span class="sd">        Raises:</span>
<span class="sd">            RuntimeError: If the reward function fails to execute successfully.</span>
<span class="sd">                This includes any exceptions that occur during function invocation.</span>

<span class="sd">        Logging:</span>
<span class="sd">            - Logs the reward function&#39;s output at DEBUG level when successful</span>
<span class="sd">            - Provides detailed error information if execution fails</span>

<span class="sd">        Notes:</span>
<span class="sd">            - Designed to be flexible with varying function signatures</span>
<span class="sd">            - Critical for validating dynamically generated reward functions</span>
<span class="sd">            - Part of the reward function generation quality control process</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">try</span><span class="p">:</span>
            <span class="n">reward</span> <span class="o">=</span> <span class="n">reward_function</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">logger</span><span class="o">.</span><span class="n">debug</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Reward function output: </span><span class="si">{</span><span class="n">reward</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
        <span class="k">except</span> <span class="ne">Exception</span> <span class="k">as</span> <span class="n">e</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">RuntimeError</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Error during reward function execution: </span><span class="si">{</span><span class="n">e</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">self_refine_reward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">idx</span><span class="p">:</span> <span class="nb">int</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Callable</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Iteratively improve a reward function using self-refinement techniques.</span>

<span class="sd">        This method implements an intelligent self-refinement process for reward functions</span>
<span class="sd">        by leveraging a Language Model (LLM) to analyze and improve the current function</span>
<span class="sd">        based on its previous performance.</span>

<span class="sd">        Key Objectives: </span>
<span class="sd">            - Analyze current reward function performance</span>
<span class="sd">            - Generate an improved version of the reward function</span>
<span class="sd">            - Maintain the core task objectives while optimizing the reward signal</span>

<span class="sd">        Args:</span>
<span class="sd">            idx (int): Index of the reward function in the memory to be refined.</span>
<span class="sd">                    Typically the worst-performing function from previous evaluation.</span>

<span class="sd">        Returns:</span>
<span class="sd">            int: Index of the newly created refined reward function in the memory.</span>

<span class="sd">        Refinement Process:</span>
<span class="sd">            1. Construct a refinement prompt with:</span>
<span class="sd">                - Current reward function code</span>
<span class="sd">                - Performance metrics</span>
<span class="sd">                - Explicit refinement goals</span>
<span class="sd">            2. Generate a new reward function using LLM</span>
<span class="sd">            3. Compile and validate the new function</span>
<span class="sd">            4. Append the new function to memory</span>
<span class="sd">            5. Return the index of the new function</span>

<span class="sd">        Refinement Goals:</span>
<span class="sd">            - Increase success rate of the policy</span>
<span class="sd">            - Optimize the reward signal for better learning</span>
<span class="sd">            - Preserve the original task objectives</span>
<span class="sd">            - Improve overall performance</span>

<span class="sd">        Notes:</span>
<span class="sd">            - Uses the existing memory to track function evolution</span>
<span class="sd">            - Leverages LLM for intelligent function refinement</span>
<span class="sd">            - Provides a systematic approach to reward function improvement</span>
<span class="sd">            - Maintains a history of function iterations</span>
<span class="sd">    &quot;&quot;&quot;</span>
        <span class="n">refinement_prompt</span> <span class="o">=</span> <span class="sa">f</span><span class="s2">&quot;&quot;&quot;</span>
<span class="s2">        improve the reward function to:</span>
<span class="s2">        - Increase success rate</span>
<span class="s2">        - Optimize reward signal</span>
<span class="s2">        - Maintain task objectives</span>

<span class="s2">        your best reward function:</span>
<span class="s2">        </span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">memory</span><span class="p">[</span><span class="n">idx</span><span class="p">]</span><span class="o">.</span><span class="n">reward_func_str</span><span class="si">}</span>

<span class="s2">        performance:</span>
<span class="s2">        </span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">memory</span><span class="p">[</span><span class="n">idx</span><span class="p">]</span><span class="o">.</span><span class="n">performances</span><span class="si">}</span>
<span class="s2">        &quot;&quot;&quot;</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">llm</span><span class="o">.</span><span class="n">add_message</span><span class="p">(</span><span class="n">refinement_prompt</span><span class="p">)</span>
        <span class="n">refined_response</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">llm</span><span class="o">.</span><span class="n">generate_response</span><span class="p">(</span><span class="n">stream</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
        <span class="n">refined_response</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">llm</span><span class="o">.</span><span class="n">print_Generator_and_return</span><span class="p">(</span><span class="n">refined_response</span><span class="p">)</span>
        <span class="n">reward_func</span><span class="p">,</span> <span class="n">refined_response</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">get_runnable_function</span><span class="p">(</span><span class="n">refined_response</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">memory</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">State</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">memory</span><span class="p">),</span> <span class="n">reward_func</span><span class="p">,</span> <span class="n">refined_response</span><span class="p">))</span>

        <span class="k">return</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">memory</span><span class="p">)</span> <span class="o">-</span> <span class="mi">1</span>

    <span class="k">def</span> <span class="nf">_learning</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">state</span><span class="p">:</span> <span class="n">State</span><span class="p">,</span> <span class="n">queue</span><span class="p">:</span> <span class="n">Queue</span> <span class="o">=</span> <span class="kc">None</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;train a policy on an environment&quot;&quot;&quot;</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">logger</span><span class="o">.</span><span class="n">debug</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;state </span><span class="si">{</span><span class="n">state</span><span class="o">.</span><span class="n">idx</span><span class="si">}</span><span class="s2"> begin is learning with reward function: </span><span class="si">{</span><span class="n">state</span><span class="o">.</span><span class="n">reward_func_str</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
        <span class="n">vec_env</span><span class="p">,</span> <span class="n">model</span><span class="p">,</span> <span class="n">numvenv</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_generate_env_model</span><span class="p">(</span><span class="n">state</span><span class="o">.</span><span class="n">reward_func</span><span class="p">)</span>
        <span class="n">training_callback</span> <span class="o">=</span> <span class="n">TrainingInfoCallback</span><span class="p">()</span>
        <span class="n">policy</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">learn</span><span class="p">(</span><span class="n">total_timesteps</span><span class="o">=</span><span class="mi">60000</span><span class="p">,</span> <span class="n">callback</span><span class="o">=</span><span class="n">training_callback</span><span class="p">)</span>
        <span class="n">policy</span><span class="o">.</span><span class="n">save</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;model/policy</span><span class="si">{</span><span class="n">state</span><span class="o">.</span><span class="n">idx</span><span class="si">}</span><span class="s2">.model&quot;</span><span class="p">)</span>
        <span class="n">metrics</span> <span class="o">=</span> <span class="n">training_callback</span><span class="o">.</span><span class="n">get_metrics</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">logger</span><span class="o">.</span><span class="n">debug</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">state</span><span class="o">.</span><span class="n">idx</span><span class="si">}</span><span class="s2"> TRAINING METRICS: </span><span class="si">{</span><span class="n">metrics</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
        <span class="n">sr_test</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">test_policy</span><span class="p">(</span><span class="n">vec_env</span><span class="p">,</span> <span class="n">policy</span><span class="p">,</span> <span class="n">numvenv</span><span class="p">)</span>
        <span class="c1"># ajoute au dict metrics les performances sans ecraser les anciennes</span>
        <span class="n">metrics</span><span class="p">[</span><span class="s2">&quot;test_success_rate&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">sr_test</span>
        <span class="k">if</span> <span class="n">os</span><span class="o">.</span><span class="n">name</span> <span class="o">==</span> <span class="s2">&quot;posix&quot;</span><span class="p">:</span>
            <span class="n">queue</span><span class="o">.</span><span class="n">put</span><span class="p">([</span><span class="n">state</span><span class="o">.</span><span class="n">idx</span><span class="p">,</span> <span class="sa">f</span><span class="s2">&quot;model/policy</span><span class="si">{</span><span class="n">state</span><span class="o">.</span><span class="n">idx</span><span class="si">}</span><span class="s2">.model&quot;</span><span class="p">,</span> <span class="n">metrics</span><span class="p">])</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">state</span><span class="o">.</span><span class="n">set_performances</span><span class="p">(</span><span class="n">metrics</span><span class="p">)</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">memory</span><span class="p">[</span><span class="n">state</span><span class="o">.</span><span class="n">idx</span><span class="p">]</span><span class="o">.</span><span class="n">set_policy</span><span class="p">(</span><span class="n">policy</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">evaluate_policy</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">idx1</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span> <span class="n">idx2</span><span class="p">:</span> <span class="nb">int</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">int</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Evaluate policy performance for multiple reward functions</span>

<span class="sd">        Args:</span>
<span class="sd">            objectives_metrics (List[callable]): Custom objective metrics</span>
<span class="sd">            num_episodes (int): Number of evaluation episodes</span>

<span class="sd">        Returns:</span>
<span class="sd">            Dict: Performance metrics for multiple reward functions</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="n">os</span><span class="o">.</span><span class="n">name</span> <span class="o">==</span> <span class="s2">&quot;posix&quot;</span><span class="p">:</span>
            <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">memory</span><span class="p">)</span> <span class="o">&lt;</span> <span class="mi">2</span><span class="p">:</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">logger</span><span class="o">.</span><span class="n">error</span><span class="p">(</span><span class="s2">&quot;At least two reward functions are required.&quot;</span><span class="p">)</span>
            <span class="n">to_join</span><span class="p">:</span> <span class="nb">list</span> <span class="o">=</span> <span class="p">[]</span>
            <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="p">[</span><span class="n">idx1</span><span class="p">,</span> <span class="n">idx2</span><span class="p">]:</span>
                <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">memory</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="o">.</span><span class="n">performances</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
                    <span class="bp">self</span><span class="o">.</span><span class="n">multi_process</span><span class="o">.</span><span class="n">append</span><span class="p">(</span>
                        <span class="n">Process</span><span class="p">(</span><span class="n">target</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">_learning</span><span class="p">,</span> <span class="n">args</span><span class="o">=</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">memory</span><span class="p">[</span><span class="n">i</span><span class="p">],</span> <span class="bp">self</span><span class="o">.</span><span class="n">queue</span><span class="p">))</span>
                    <span class="p">)</span>
                    <span class="bp">self</span><span class="o">.</span><span class="n">multi_process</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">start</span><span class="p">()</span>
                    <span class="bp">self</span><span class="o">.</span><span class="n">to_get</span> <span class="o">+=</span> <span class="mi">1</span>
                    <span class="n">to_join</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">multi_process</span><span class="p">)</span><span class="o">-</span><span class="mi">1</span><span class="p">)</span>

            <span class="k">while</span> <span class="bp">self</span><span class="o">.</span><span class="n">to_get</span> <span class="o">!=</span> <span class="mi">0</span><span class="p">:</span>
                <span class="k">try</span><span class="p">:</span>
                    <span class="n">get</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">queue</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="n">block</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
                    <span class="bp">self</span><span class="o">.</span><span class="n">memory</span><span class="p">[</span><span class="n">get</span><span class="p">[</span><span class="mi">0</span><span class="p">]]</span><span class="o">.</span><span class="n">set_policy</span><span class="p">(</span><span class="n">get</span><span class="p">[</span><span class="mi">1</span><span class="p">])</span>
                    <span class="bp">self</span><span class="o">.</span><span class="n">memory</span><span class="p">[</span><span class="n">get</span><span class="p">[</span><span class="mi">0</span><span class="p">]]</span><span class="o">.</span><span class="n">set_performances</span><span class="p">(</span><span class="n">get</span><span class="p">[</span><span class="mi">2</span><span class="p">])</span>
                    <span class="bp">self</span><span class="o">.</span><span class="n">logger</span><span class="o">.</span><span class="n">debug</span><span class="p">(</span>
                        <span class="sa">f</span><span class="s2">&quot;state </span><span class="si">{</span><span class="n">get</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="si">}</span><span class="s2"> has finished learning with performances: </span><span class="si">{</span><span class="n">get</span><span class="p">[</span><span class="mi">2</span><span class="p">]</span><span class="si">}</span><span class="s2">&quot;</span>
                    <span class="p">)</span>
                    <span class="bp">self</span><span class="o">.</span><span class="n">to_get</span> <span class="o">-=</span> <span class="mi">1</span>
                <span class="k">except</span> <span class="n">Empty</span><span class="p">:</span>
                    <span class="n">sleep</span><span class="p">(</span><span class="mf">0.1</span><span class="p">)</span>

            <span class="k">for</span> <span class="n">p</span> <span class="ow">in</span> <span class="n">to_join</span><span class="p">:</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">multi_process</span><span class="p">[</span><span class="n">p</span><span class="p">]</span><span class="o">.</span><span class="n">join</span><span class="p">()</span>
            <span class="k">if</span> <span class="p">(</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">memory</span><span class="p">[</span><span class="n">idx1</span><span class="p">]</span><span class="o">.</span><span class="n">performances</span><span class="p">[</span><span class="s2">&quot;test_success_rate&quot;</span><span class="p">]</span>
                <span class="o">&gt;</span> <span class="bp">self</span><span class="o">.</span><span class="n">memory</span><span class="p">[</span><span class="n">idx2</span><span class="p">]</span><span class="o">.</span><span class="n">performances</span><span class="p">[</span><span class="s2">&quot;test_success_rate&quot;</span><span class="p">]</span>
            <span class="p">):</span>
                <span class="k">return</span> <span class="n">idx1</span><span class="p">,</span> <span class="n">idx2</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="k">return</span> <span class="n">idx2</span><span class="p">,</span> <span class="n">idx1</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">memory</span><span class="p">)</span> <span class="o">&lt;</span> <span class="mi">2</span><span class="p">:</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">logger</span><span class="o">.</span><span class="n">error</span><span class="p">(</span><span class="s2">&quot;At least two reward functions are required.&quot;</span><span class="p">)</span>
            <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="p">[</span><span class="n">idx1</span><span class="p">,</span> <span class="n">idx2</span><span class="p">]:</span>
                <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">memory</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="o">.</span><span class="n">performances</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
                    <span class="bp">self</span><span class="o">.</span><span class="n">_learning</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">memory</span><span class="p">[</span><span class="n">i</span><span class="p">])</span>
            <span class="c1"># TODO comparaison sur le success rate pour l&#39;instant</span>
            <span class="k">if</span> <span class="p">(</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">memory</span><span class="p">[</span><span class="n">idx1</span><span class="p">]</span><span class="o">.</span><span class="n">performances</span><span class="p">[</span><span class="s2">&quot;test_success_rate&quot;</span><span class="p">]</span>
                <span class="o">&gt;</span> <span class="bp">self</span><span class="o">.</span><span class="n">memory</span><span class="p">[</span><span class="n">idx2</span><span class="p">]</span><span class="o">.</span><span class="n">performances</span><span class="p">[</span><span class="s2">&quot;test_success_rate&quot;</span><span class="p">]</span>
            <span class="p">):</span>
                <span class="k">return</span> <span class="n">idx1</span><span class="p">,</span> <span class="n">idx2</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="k">return</span> <span class="n">idx2</span><span class="p">,</span> <span class="n">idx1</span>

    <span class="k">def</span> <span class="nf">test_policy</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">env</span><span class="p">,</span>
        <span class="n">policy</span><span class="p">,</span>
        <span class="n">numvenv</span><span class="p">,</span>
        <span class="n">nb_episodes</span><span class="o">=</span><span class="mi">100</span><span class="p">,</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">float</span><span class="p">:</span>
        <span class="n">all_rewards</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="n">nb_success</span> <span class="o">=</span> <span class="mi">0</span>

        <span class="n">obs</span> <span class="o">=</span> <span class="n">env</span><span class="o">.</span><span class="n">reset</span><span class="p">()</span>

        <span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">nb_episodes</span> <span class="o">//</span> <span class="n">numvenv</span><span class="p">):</span>
            <span class="n">episode_rewards</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">numvenv</span><span class="p">)</span>
            <span class="n">dones</span> <span class="o">=</span> <span class="p">[</span><span class="kc">False</span><span class="p">]</span> <span class="o">*</span> <span class="n">numvenv</span>

            <span class="k">while</span> <span class="ow">not</span> <span class="nb">all</span><span class="p">(</span><span class="n">dones</span><span class="p">):</span>
                <span class="n">actions</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="n">policy</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">obs</span><span class="p">)</span>
                <span class="n">obs</span><span class="p">,</span> <span class="n">rewards</span><span class="p">,</span> <span class="n">new_dones</span><span class="p">,</span> <span class="n">infos</span> <span class="o">=</span> <span class="n">env</span><span class="o">.</span><span class="n">step</span><span class="p">(</span><span class="n">actions</span><span class="p">)</span>
                <span class="n">episode_rewards</span> <span class="o">+=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">rewards</span><span class="p">)</span>
                <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="p">(</span><span class="n">done</span><span class="p">,</span> <span class="n">info</span><span class="p">)</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="nb">zip</span><span class="p">(</span><span class="n">new_dones</span><span class="p">,</span> <span class="n">infos</span><span class="p">)):</span>
                    <span class="k">if</span> <span class="n">done</span><span class="p">:</span>
                        <span class="n">dones</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="kc">True</span>
                        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">success_function</span><span class="p">(</span><span class="n">env</span><span class="o">.</span><span class="n">envs</span><span class="p">[</span><span class="n">i</span><span class="p">],</span> <span class="n">info</span><span class="p">):</span>
                            <span class="n">nb_success</span> <span class="o">+=</span> <span class="mi">1</span>

            <span class="n">all_rewards</span><span class="o">.</span><span class="n">extend</span><span class="p">(</span><span class="n">episode_rewards</span><span class="p">)</span>

        <span class="n">success_rate</span> <span class="o">=</span> <span class="n">nb_success</span> <span class="o">/</span> <span class="n">nb_episodes</span>
        <span class="k">return</span> <span class="n">success_rate</span>

    <span class="k">def</span> <span class="nf">_generate_env_model</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">reward_func</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Generate the environment model</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">numenvs</span> <span class="o">=</span> <span class="mi">2</span>
        <span class="c1"># SubprocVecEnv sauf on utilisera cuda derrire</span>
        <span class="n">vec_env</span> <span class="o">=</span> <span class="n">make_vec_env</span><span class="p">(</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">env_type</span><span class="o">.</span><span class="n">value</span><span class="p">,</span> 
            <span class="n">n_envs</span><span class="o">=</span><span class="n">numenvs</span><span class="p">,</span> 
            <span class="n">wrapper_class</span><span class="o">=</span><span class="n">CustomRewardWrapper</span><span class="p">,</span> 
            <span class="n">wrapper_kwargs</span><span class="o">=</span><span class="p">{</span><span class="s2">&quot;llm_reward_function&quot;</span><span class="p">:</span> <span class="n">reward_func</span><span class="p">})</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">learning_algo</span> <span class="o">==</span> <span class="n">Algo</span><span class="o">.</span><span class="n">PPO</span><span class="p">:</span>
            <span class="n">model</span> <span class="o">=</span> <span class="n">PPO</span><span class="p">(</span><span class="s2">&quot;MlpPolicy&quot;</span><span class="p">,</span> <span class="n">vec_env</span><span class="p">,</span> <span class="n">verbose</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="s2">&quot;cpu&quot;</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;The learning algorithm is not implemented.&quot;</span><span class="p">)</span>

        <span class="k">return</span> <span class="n">vec_env</span><span class="p">,</span> <span class="n">model</span><span class="p">,</span> <span class="n">numenvs</span>
</code></pre></div></td></tr></table></div>
              </details>



  <div class="doc doc-children">









<div class="doc doc-object doc-function">


<h3 id="src.VIRAL.VIRAL.__init__" class="doc doc-heading">
            <code class="highlight language-python"><span class="fm">__init__</span><span class="p">(</span><span class="n">learning_algo</span><span class="p">,</span> <span class="n">env_type</span><span class="p">,</span> <span class="n">success_function</span><span class="p">,</span> <span class="n">objectives_metrics</span><span class="o">=</span><span class="p">[],</span> <span class="n">model</span><span class="o">=</span><span class="s1">&#39;qwen2.5-coder&#39;</span><span class="p">,</span> <span class="n">options</span><span class="o">=</span><span class="p">{})</span></code>

</h3>


    <div class="doc doc-contents ">

        <p>Initialize VIRAL architecture for dynamic reward function generation
    Args:
        model (str): Language model for reward generation
        learning_method (str): Reinforcement learning method</p>

            <details class="quote">
              <summary>Source code in <code>src/VIRAL.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">28</span>
<span class="normal">29</span>
<span class="normal">30</span>
<span class="normal">31</span>
<span class="normal">32</span>
<span class="normal">33</span>
<span class="normal">34</span>
<span class="normal">35</span>
<span class="normal">36</span>
<span class="normal">37</span>
<span class="normal">38</span>
<span class="normal">39</span>
<span class="normal">40</span>
<span class="normal">41</span>
<span class="normal">42</span>
<span class="normal">43</span>
<span class="normal">44</span>
<span class="normal">45</span>
<span class="normal">46</span>
<span class="normal">47</span>
<span class="normal">48</span>
<span class="normal">49</span>
<span class="normal">50</span>
<span class="normal">51</span>
<span class="normal">52</span>
<span class="normal">53</span>
<span class="normal">54</span>
<span class="normal">55</span>
<span class="normal">56</span>
<span class="normal">57</span>
<span class="normal">58</span>
<span class="normal">59</span>
<span class="normal">60</span>
<span class="normal">61</span>
<span class="normal">62</span>
<span class="normal">63</span>
<span class="normal">64</span>
<span class="normal">65</span>
<span class="normal">66</span>
<span class="normal">67</span>
<span class="normal">68</span>
<span class="normal">69</span>
<span class="normal">70</span>
<span class="normal">71</span>
<span class="normal">72</span>
<span class="normal">73</span>
<span class="normal">74</span>
<span class="normal">75</span>
<span class="normal">76</span>
<span class="normal">77</span>
<span class="normal">78</span>
<span class="normal">79</span>
<span class="normal">80</span>
<span class="normal">81</span>
<span class="normal">82</span>
<span class="normal">83</span>
<span class="normal">84</span>
<span class="normal">85</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span>
    <span class="bp">self</span><span class="p">,</span>
    <span class="n">learning_algo</span><span class="p">:</span> <span class="n">Algo</span><span class="p">,</span>
    <span class="n">env_type</span> <span class="p">:</span> <span class="n">Environments</span><span class="p">,</span>
    <span class="n">success_function</span><span class="p">:</span> <span class="n">Callable</span><span class="p">,</span>
    <span class="n">objectives_metrics</span><span class="p">:</span> <span class="n">List</span><span class="p">[</span><span class="nb">callable</span><span class="p">]</span> <span class="o">=</span> <span class="p">[],</span>
    <span class="n">model</span><span class="p">:</span> <span class="nb">str</span> <span class="o">=</span> <span class="s2">&quot;qwen2.5-coder&quot;</span><span class="p">,</span>
    <span class="n">options</span><span class="p">:</span> <span class="nb">dict</span> <span class="o">=</span> <span class="p">{},</span>
<span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Initialize VIRAL architecture for dynamic reward function generation</span>
<span class="sd">        Args:</span>
<span class="sd">            model (str): Language model for reward generation</span>
<span class="sd">            learning_method (str): Reinforcement learning method</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">if</span> <span class="n">options</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">&quot;seed&quot;</span><span class="p">)</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
        <span class="n">options</span><span class="p">[</span><span class="s2">&quot;seed&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">random</span><span class="o">.</span><span class="n">randint</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1000000</span><span class="p">)</span>

    <span class="bp">self</span><span class="o">.</span><span class="n">llm</span> <span class="o">=</span> <span class="n">OllamaChat</span><span class="p">(</span>
        <span class="n">model</span><span class="o">=</span><span class="n">model</span><span class="p">,</span>
        <span class="n">system_prompt</span><span class="o">=</span><span class="s2">&quot;&quot;&quot;</span>
<span class="s2">    You are an expert in Reinforcement Learning specialized in designing reward functions.</span>
<span class="s2">    Strict criteria:</span>
<span class="s2">    - Complete ONLY the reward function code</span>
<span class="s2">    - Use Python format</span>
<span class="s2">    - Give no additional explanations</span>
<span class="s2">    - Focus on the Gymnasium environment </span>
<span class="s2">    - Take into the observation of the state, the terminated and truncated boolean</span>
<span class="s2">    - STOP immediately your completion after the last return</span>
<span class="s2">    &quot;&quot;&quot;</span><span class="p">,</span>
        <span class="n">options</span><span class="o">=</span><span class="n">options</span><span class="p">,</span>
    <span class="p">)</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">env_type</span> <span class="p">:</span> <span class="n">Environments</span> <span class="o">=</span> <span class="n">env_type</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">success_function</span> <span class="o">=</span> <span class="n">success_function</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">env</span> <span class="o">=</span> <span class="kc">None</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">objectives_metrics</span> <span class="o">=</span> <span class="n">objectives_metrics</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">learning_algo</span><span class="p">:</span> <span class="n">Algo</span> <span class="o">=</span> <span class="n">learning_algo</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">learning_method</span> <span class="o">=</span> <span class="kc">None</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">logger</span> <span class="o">=</span> <span class="n">getLogger</span><span class="p">(</span><span class="s2">&quot;VIRAL&quot;</span><span class="p">)</span>
    <span class="c1"># self._learning(self.memory[0])</span>

    <span class="k">if</span> <span class="n">os</span><span class="o">.</span><span class="n">name</span> <span class="o">==</span> <span class="s2">&quot;posix&quot;</span><span class="p">:</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">queue</span> <span class="o">=</span> <span class="n">Queue</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">memory</span><span class="p">:</span> <span class="n">List</span><span class="p">[</span><span class="n">State</span><span class="p">]</span> <span class="o">=</span> <span class="p">[</span><span class="n">State</span><span class="p">(</span><span class="mi">0</span><span class="p">)]</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">multi_process</span><span class="p">:</span> <span class="nb">list</span><span class="p">[</span><span class="n">Process</span><span class="p">]</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">multi_process</span><span class="o">.</span><span class="n">append</span><span class="p">(</span>
            <span class="n">Process</span><span class="p">(</span>
                <span class="n">target</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">_learning</span><span class="p">,</span>
                <span class="n">args</span><span class="o">=</span><span class="p">(</span>
                    <span class="bp">self</span><span class="o">.</span><span class="n">memory</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span>
                    <span class="bp">self</span><span class="o">.</span><span class="n">queue</span><span class="p">,</span>
                <span class="p">),</span>
            <span class="p">)</span>
        <span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">multi_process</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">start</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">to_get</span> <span class="o">=</span> <span class="mi">1</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">memory</span><span class="p">:</span> <span class="n">List</span><span class="p">[</span><span class="n">State</span><span class="p">]</span> <span class="o">=</span> <span class="p">[</span><span class="n">State</span><span class="p">(</span><span class="mi">0</span><span class="p">)]</span>
</code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>

<div class="doc doc-object doc-function">


<h3 id="src.VIRAL.VIRAL.compile_reward_function" class="doc doc-heading">
            <code class="highlight language-python"><span class="n">compile_reward_function</span><span class="p">(</span><span class="n">response</span><span class="p">)</span></code>

</h3>


    <div class="doc doc-contents ">

        <p>Compile a reward function dynamically from a string response.</p>
<p>This method takes a code string representing a reward function and dynamically 
compiles it into an executable Python function. It provides a secure way to 
generate reward functions for reinforcement learning environments.</p>


<details class="key-features" open>
  <summary>Key Features</summary>
  <ul>
<li>Dynamically executes code in an isolated global namespace</li>
<li>Provides access to NumPy functions</li>
<li>Extracts the compiled function by its name</li>
<li>Robust error handling for syntax issues</li>
</ul>
</details>

<p><span class="doc-section-title">Parameters:</span></p>
    <table>
      <thead>
        <tr>
          <th>Name</th>
          <th>Type</th>
          <th>Description</th>
          <th>Default</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td>
                <code>response</code>
            </td>
            <td>
                  <code>str</code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>A string containing a complete Python function definition 
            for a reward function.</p>
              </div>
            </td>
            <td>
                <em>required</em>
            </td>
          </tr>
      </tbody>
    </table>


    <p><span class="doc-section-title">Returns:</span></p>
    <table>
      <thead>
        <tr>
<th>Name</th>          <th>Type</th>
          <th>Description</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
<td><code>Callable</code></td>            <td>
                  <code><span title="typing.Callable">Callable</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>The compiled reward function that can be called with appropriate 
    arguments in a gym environment.</p>
              </div>
            </td>
          </tr>
      </tbody>
    </table>


<p><span class="doc-section-title">Raises:</span></p>
    <table>
      <thead>
        <tr>
          <th>Type</th>
          <th>Description</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td>
                  <code>SyntaxError</code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>If the provided code contains invalid Python syntax.</p>
              </div>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                  <code>ValueError</code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>If the function cannot be extracted from the compiled namespace.</p>
              </div>
            </td>
          </tr>
      </tbody>
    </table>


<details class="notes" open>
  <summary>Notes</summary>
  <ul>
<li>Uses <code>exec()</code> for dynamic code compilation</li>
<li>Provides NumPy (<code>np</code>) in the execution namespace</li>
<li>Assumes the last function defined in the response is the reward function</li>
</ul>
</details>
            <details class="quote">
              <summary>Source code in <code>src/VIRAL.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">282</span>
<span class="normal">283</span>
<span class="normal">284</span>
<span class="normal">285</span>
<span class="normal">286</span>
<span class="normal">287</span>
<span class="normal">288</span>
<span class="normal">289</span>
<span class="normal">290</span>
<span class="normal">291</span>
<span class="normal">292</span>
<span class="normal">293</span>
<span class="normal">294</span>
<span class="normal">295</span>
<span class="normal">296</span>
<span class="normal">297</span>
<span class="normal">298</span>
<span class="normal">299</span>
<span class="normal">300</span>
<span class="normal">301</span>
<span class="normal">302</span>
<span class="normal">303</span>
<span class="normal">304</span>
<span class="normal">305</span>
<span class="normal">306</span>
<span class="normal">307</span>
<span class="normal">308</span>
<span class="normal">309</span>
<span class="normal">310</span>
<span class="normal">311</span>
<span class="normal">312</span>
<span class="normal">313</span>
<span class="normal">314</span>
<span class="normal">315</span>
<span class="normal">316</span>
<span class="normal">317</span>
<span class="normal">318</span>
<span class="normal">319</span>
<span class="normal">320</span>
<span class="normal">321</span>
<span class="normal">322</span>
<span class="normal">323</span>
<span class="normal">324</span>
<span class="normal">325</span>
<span class="normal">326</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">def</span> <span class="nf">compile_reward_function</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">response</span><span class="p">:</span> <span class="nb">str</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Callable</span><span class="p">:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Compile a reward function dynamically from a string response.</span>

<span class="sd">    This method takes a code string representing a reward function and dynamically </span>
<span class="sd">    compiles it into an executable Python function. It provides a secure way to </span>
<span class="sd">    generate reward functions for reinforcement learning environments.</span>

<span class="sd">    Key Features:</span>
<span class="sd">        - Dynamically executes code in an isolated global namespace</span>
<span class="sd">        - Provides access to NumPy functions</span>
<span class="sd">        - Extracts the compiled function by its name</span>
<span class="sd">        - Robust error handling for syntax issues</span>

<span class="sd">    Args:</span>
<span class="sd">        response (str): A string containing a complete Python function definition </span>
<span class="sd">                        for a reward function.</span>

<span class="sd">    Returns:</span>
<span class="sd">        Callable: The compiled reward function that can be called with appropriate </span>
<span class="sd">                arguments in a gym environment.</span>

<span class="sd">    Raises:</span>
<span class="sd">        SyntaxError: If the provided code contains invalid Python syntax.</span>
<span class="sd">        ValueError: If the function cannot be extracted from the compiled namespace.</span>

<span class="sd">    Notes:</span>
<span class="sd">        - Uses `exec()` for dynamic code compilation</span>
<span class="sd">        - Provides NumPy (`np`) in the execution namespace</span>
<span class="sd">        - Assumes the last function defined in the response is the reward function</span>
<span class="sd">&quot;&quot;&quot;</span>

    <span class="n">exec_globals</span> <span class="o">=</span> <span class="p">{}</span>
    <span class="n">exec_globals</span><span class="p">[</span><span class="s2">&quot;np&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">np</span>
    <span class="k">try</span><span class="p">:</span>
        <span class="n">exec</span><span class="p">(</span><span class="n">response</span><span class="p">,</span> <span class="n">exec_globals</span><span class="p">)</span>
    <span class="k">except</span> <span class="ne">SyntaxError</span> <span class="k">as</span> <span class="n">e</span><span class="p">:</span>
        <span class="k">raise</span> <span class="ne">SyntaxError</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Syntax error in the generated code : </span><span class="si">{</span><span class="n">e</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>

    <span class="n">reward_function_name</span> <span class="o">=</span> <span class="n">response</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="s2">&quot;(&quot;</span><span class="p">)[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">split</span><span class="p">()[</span>
        <span class="o">-</span><span class="mi">1</span>
    <span class="p">]</span>  <span class="c1"># rcup le nom de la fonction</span>
    <span class="n">reward_function</span> <span class="o">=</span> <span class="n">exec_globals</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="n">reward_function_name</span><span class="p">)</span>

    <span class="k">return</span> <span class="n">reward_function</span>
</code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>

<div class="doc doc-object doc-function">


<h3 id="src.VIRAL.VIRAL.evaluate_policy" class="doc doc-heading">
            <code class="highlight language-python"><span class="n">evaluate_policy</span><span class="p">(</span><span class="n">idx1</span><span class="p">,</span> <span class="n">idx2</span><span class="p">)</span></code>

</h3>


    <div class="doc doc-contents ">

        <p>Evaluate policy performance for multiple reward functions</p>


<p><span class="doc-section-title">Parameters:</span></p>
    <table>
      <thead>
        <tr>
          <th>Name</th>
          <th>Type</th>
          <th>Description</th>
          <th>Default</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td>
                <code>objectives_metrics</code>
            </td>
            <td>
                  <code><span title="typing.List">List</span>[callable]</code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Custom objective metrics</p>
              </div>
            </td>
            <td>
                <em>required</em>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>num_episodes</code>
            </td>
            <td>
                  <code>int</code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Number of evaluation episodes</p>
              </div>
            </td>
            <td>
                <em>required</em>
            </td>
          </tr>
      </tbody>
    </table>


    <p><span class="doc-section-title">Returns:</span></p>
    <table>
      <thead>
        <tr>
<th>Name</th>          <th>Type</th>
          <th>Description</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
<td><code>Dict</code></td>            <td>
                  <code>int</code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Performance metrics for multiple reward functions</p>
              </div>
            </td>
          </tr>
      </tbody>
    </table>

            <details class="quote">
              <summary>Source code in <code>src/VIRAL.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">448</span>
<span class="normal">449</span>
<span class="normal">450</span>
<span class="normal">451</span>
<span class="normal">452</span>
<span class="normal">453</span>
<span class="normal">454</span>
<span class="normal">455</span>
<span class="normal">456</span>
<span class="normal">457</span>
<span class="normal">458</span>
<span class="normal">459</span>
<span class="normal">460</span>
<span class="normal">461</span>
<span class="normal">462</span>
<span class="normal">463</span>
<span class="normal">464</span>
<span class="normal">465</span>
<span class="normal">466</span>
<span class="normal">467</span>
<span class="normal">468</span>
<span class="normal">469</span>
<span class="normal">470</span>
<span class="normal">471</span>
<span class="normal">472</span>
<span class="normal">473</span>
<span class="normal">474</span>
<span class="normal">475</span>
<span class="normal">476</span>
<span class="normal">477</span>
<span class="normal">478</span>
<span class="normal">479</span>
<span class="normal">480</span>
<span class="normal">481</span>
<span class="normal">482</span>
<span class="normal">483</span>
<span class="normal">484</span>
<span class="normal">485</span>
<span class="normal">486</span>
<span class="normal">487</span>
<span class="normal">488</span>
<span class="normal">489</span>
<span class="normal">490</span>
<span class="normal">491</span>
<span class="normal">492</span>
<span class="normal">493</span>
<span class="normal">494</span>
<span class="normal">495</span>
<span class="normal">496</span>
<span class="normal">497</span>
<span class="normal">498</span>
<span class="normal">499</span>
<span class="normal">500</span>
<span class="normal">501</span>
<span class="normal">502</span>
<span class="normal">503</span>
<span class="normal">504</span>
<span class="normal">505</span>
<span class="normal">506</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">def</span> <span class="nf">evaluate_policy</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">idx1</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span> <span class="n">idx2</span><span class="p">:</span> <span class="nb">int</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">int</span><span class="p">:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Evaluate policy performance for multiple reward functions</span>

<span class="sd">    Args:</span>
<span class="sd">        objectives_metrics (List[callable]): Custom objective metrics</span>
<span class="sd">        num_episodes (int): Number of evaluation episodes</span>

<span class="sd">    Returns:</span>
<span class="sd">        Dict: Performance metrics for multiple reward functions</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">if</span> <span class="n">os</span><span class="o">.</span><span class="n">name</span> <span class="o">==</span> <span class="s2">&quot;posix&quot;</span><span class="p">:</span>
        <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">memory</span><span class="p">)</span> <span class="o">&lt;</span> <span class="mi">2</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">logger</span><span class="o">.</span><span class="n">error</span><span class="p">(</span><span class="s2">&quot;At least two reward functions are required.&quot;</span><span class="p">)</span>
        <span class="n">to_join</span><span class="p">:</span> <span class="nb">list</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="p">[</span><span class="n">idx1</span><span class="p">,</span> <span class="n">idx2</span><span class="p">]:</span>
            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">memory</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="o">.</span><span class="n">performances</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">multi_process</span><span class="o">.</span><span class="n">append</span><span class="p">(</span>
                    <span class="n">Process</span><span class="p">(</span><span class="n">target</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">_learning</span><span class="p">,</span> <span class="n">args</span><span class="o">=</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">memory</span><span class="p">[</span><span class="n">i</span><span class="p">],</span> <span class="bp">self</span><span class="o">.</span><span class="n">queue</span><span class="p">))</span>
                <span class="p">)</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">multi_process</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">start</span><span class="p">()</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">to_get</span> <span class="o">+=</span> <span class="mi">1</span>
                <span class="n">to_join</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">multi_process</span><span class="p">)</span><span class="o">-</span><span class="mi">1</span><span class="p">)</span>

        <span class="k">while</span> <span class="bp">self</span><span class="o">.</span><span class="n">to_get</span> <span class="o">!=</span> <span class="mi">0</span><span class="p">:</span>
            <span class="k">try</span><span class="p">:</span>
                <span class="n">get</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">queue</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="n">block</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">memory</span><span class="p">[</span><span class="n">get</span><span class="p">[</span><span class="mi">0</span><span class="p">]]</span><span class="o">.</span><span class="n">set_policy</span><span class="p">(</span><span class="n">get</span><span class="p">[</span><span class="mi">1</span><span class="p">])</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">memory</span><span class="p">[</span><span class="n">get</span><span class="p">[</span><span class="mi">0</span><span class="p">]]</span><span class="o">.</span><span class="n">set_performances</span><span class="p">(</span><span class="n">get</span><span class="p">[</span><span class="mi">2</span><span class="p">])</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">logger</span><span class="o">.</span><span class="n">debug</span><span class="p">(</span>
                    <span class="sa">f</span><span class="s2">&quot;state </span><span class="si">{</span><span class="n">get</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="si">}</span><span class="s2"> has finished learning with performances: </span><span class="si">{</span><span class="n">get</span><span class="p">[</span><span class="mi">2</span><span class="p">]</span><span class="si">}</span><span class="s2">&quot;</span>
                <span class="p">)</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">to_get</span> <span class="o">-=</span> <span class="mi">1</span>
            <span class="k">except</span> <span class="n">Empty</span><span class="p">:</span>
                <span class="n">sleep</span><span class="p">(</span><span class="mf">0.1</span><span class="p">)</span>

        <span class="k">for</span> <span class="n">p</span> <span class="ow">in</span> <span class="n">to_join</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">multi_process</span><span class="p">[</span><span class="n">p</span><span class="p">]</span><span class="o">.</span><span class="n">join</span><span class="p">()</span>
        <span class="k">if</span> <span class="p">(</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">memory</span><span class="p">[</span><span class="n">idx1</span><span class="p">]</span><span class="o">.</span><span class="n">performances</span><span class="p">[</span><span class="s2">&quot;test_success_rate&quot;</span><span class="p">]</span>
            <span class="o">&gt;</span> <span class="bp">self</span><span class="o">.</span><span class="n">memory</span><span class="p">[</span><span class="n">idx2</span><span class="p">]</span><span class="o">.</span><span class="n">performances</span><span class="p">[</span><span class="s2">&quot;test_success_rate&quot;</span><span class="p">]</span>
        <span class="p">):</span>
            <span class="k">return</span> <span class="n">idx1</span><span class="p">,</span> <span class="n">idx2</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">return</span> <span class="n">idx2</span><span class="p">,</span> <span class="n">idx1</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">memory</span><span class="p">)</span> <span class="o">&lt;</span> <span class="mi">2</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">logger</span><span class="o">.</span><span class="n">error</span><span class="p">(</span><span class="s2">&quot;At least two reward functions are required.&quot;</span><span class="p">)</span>
        <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="p">[</span><span class="n">idx1</span><span class="p">,</span> <span class="n">idx2</span><span class="p">]:</span>
            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">memory</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="o">.</span><span class="n">performances</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">_learning</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">memory</span><span class="p">[</span><span class="n">i</span><span class="p">])</span>
        <span class="c1"># TODO comparaison sur le success rate pour l&#39;instant</span>
        <span class="k">if</span> <span class="p">(</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">memory</span><span class="p">[</span><span class="n">idx1</span><span class="p">]</span><span class="o">.</span><span class="n">performances</span><span class="p">[</span><span class="s2">&quot;test_success_rate&quot;</span><span class="p">]</span>
            <span class="o">&gt;</span> <span class="bp">self</span><span class="o">.</span><span class="n">memory</span><span class="p">[</span><span class="n">idx2</span><span class="p">]</span><span class="o">.</span><span class="n">performances</span><span class="p">[</span><span class="s2">&quot;test_success_rate&quot;</span><span class="p">]</span>
        <span class="p">):</span>
            <span class="k">return</span> <span class="n">idx1</span><span class="p">,</span> <span class="n">idx2</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">return</span> <span class="n">idx2</span><span class="p">,</span> <span class="n">idx1</span>
</code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>

<div class="doc doc-object doc-function">


<h3 id="src.VIRAL.VIRAL.generate_reward_function" class="doc doc-heading">
            <code class="highlight language-python"><span class="n">generate_reward_function</span><span class="p">(</span><span class="n">task_description</span><span class="p">,</span> <span class="n">iterations</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span></code>

</h3>


    <div class="doc doc-contents ">

        <p>Generate and iteratively improve a reward function using a Language Model (LLM).</p>
<p>This method implements a sophisticated reward function generation process 
that involves multiple stages of creation, evaluation, and refinement.</p>


<details class="key-stages" open>
  <summary>Key Stages</summary>
  <ol>
<li>Initial Function Generation: Create two initial reward function candidates</li>
<li>Evaluation: Compare and identify the best and worst performing functions</li>
<li>Iterative Refinement: Progressively improve the worst-performing function</li>
</ol>
</details>

<p><span class="doc-section-title">Parameters:</span></p>
    <table>
      <thead>
        <tr>
          <th>Name</th>
          <th>Type</th>
          <th>Description</th>
          <th>Default</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td>
                <code>task_description</code>
            </td>
            <td>
                  <code>str</code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>A detailed description of the task or environment 
                    for which the reward function is being generated.</p>
              </div>
            </td>
            <td>
                <em>required</em>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>iterations</code>
            </td>
            <td>
                  <code>int</code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Number of refinement iterations to perform. 
                        Defaults to 1.</p>
              </div>
            </td>
            <td>
                  <code>1</code>
            </td>
          </tr>
      </tbody>
    </table>


    <p><span class="doc-section-title">Returns:</span></p>
    <table>
      <thead>
        <tr>
          <th>Type</th>
          <th>Description</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td>
                  <code><span title="typing.List">List</span>[<span title="utils.State.State">State</span>]</code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>List[State]: A list of generated and refined reward function states, 
        containing information about each function's performance 
        and implementation.</p>
              </div>
            </td>
          </tr>
      </tbody>
    </table>


<details class="process-overview" open>
  <summary>Process Overview</summary>
  <ul>
<li>Generates two initial reward functions using an LLM</li>
<li>Evaluates these functions using a policy evaluation method</li>
<li>Selects the worst-performing function for refinement</li>
<li>Iteratively refines the function through self-refinement</li>
<li>Tracks the evolution of reward functions in the memory</li>
</ul>
</details>

<details class="detailed-workflow" open>
  <summary>Detailed Workflow</summary>
  <ol>
<li>Generate two initial reward functions<ul>
<li>Uses a predefined prompt template</li>
<li>Applies configurable LLM generation options</li>
<li>Compiles and tests each generated function</li>
</ul>
</li>
<li>Evaluates initial functions<ul>
<li>Identifies best and worst performing functions</li>
</ul>
</li>
<li>Iterative Refinement<ul>
<li>Applies self-refinement to the worst-performing function</li>
<li>Re-evaluates after each refinement</li>
<li>Repeats for specified number of iterations</li>
</ul>
</li>
</ol>
</details>

<details class="note" open>
  <summary>Note</summary>
  <ul>
<li>Uses dynamic LLM configuration options</li>
<li>Supports flexible environment types</li>
<li>Provides a systematic approach to reward function generation</li>
<li>Logging at various stages for debugging and tracking</li>
</ul>
</details>
            <details class="quote">
              <summary>Source code in <code>src/VIRAL.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal"> 88</span>
<span class="normal"> 89</span>
<span class="normal"> 90</span>
<span class="normal"> 91</span>
<span class="normal"> 92</span>
<span class="normal"> 93</span>
<span class="normal"> 94</span>
<span class="normal"> 95</span>
<span class="normal"> 96</span>
<span class="normal"> 97</span>
<span class="normal"> 98</span>
<span class="normal"> 99</span>
<span class="normal">100</span>
<span class="normal">101</span>
<span class="normal">102</span>
<span class="normal">103</span>
<span class="normal">104</span>
<span class="normal">105</span>
<span class="normal">106</span>
<span class="normal">107</span>
<span class="normal">108</span>
<span class="normal">109</span>
<span class="normal">110</span>
<span class="normal">111</span>
<span class="normal">112</span>
<span class="normal">113</span>
<span class="normal">114</span>
<span class="normal">115</span>
<span class="normal">116</span>
<span class="normal">117</span>
<span class="normal">118</span>
<span class="normal">119</span>
<span class="normal">120</span>
<span class="normal">121</span>
<span class="normal">122</span>
<span class="normal">123</span>
<span class="normal">124</span>
<span class="normal">125</span>
<span class="normal">126</span>
<span class="normal">127</span>
<span class="normal">128</span>
<span class="normal">129</span>
<span class="normal">130</span>
<span class="normal">131</span>
<span class="normal">132</span>
<span class="normal">133</span>
<span class="normal">134</span>
<span class="normal">135</span>
<span class="normal">136</span>
<span class="normal">137</span>
<span class="normal">138</span>
<span class="normal">139</span>
<span class="normal">140</span>
<span class="normal">141</span>
<span class="normal">142</span>
<span class="normal">143</span>
<span class="normal">144</span>
<span class="normal">145</span>
<span class="normal">146</span>
<span class="normal">147</span>
<span class="normal">148</span>
<span class="normal">149</span>
<span class="normal">150</span>
<span class="normal">151</span>
<span class="normal">152</span>
<span class="normal">153</span>
<span class="normal">154</span>
<span class="normal">155</span>
<span class="normal">156</span>
<span class="normal">157</span>
<span class="normal">158</span>
<span class="normal">159</span>
<span class="normal">160</span>
<span class="normal">161</span>
<span class="normal">162</span>
<span class="normal">163</span>
<span class="normal">164</span>
<span class="normal">165</span>
<span class="normal">166</span>
<span class="normal">167</span>
<span class="normal">168</span>
<span class="normal">169</span>
<span class="normal">170</span>
<span class="normal">171</span>
<span class="normal">172</span>
<span class="normal">173</span>
<span class="normal">174</span>
<span class="normal">175</span>
<span class="normal">176</span>
<span class="normal">177</span>
<span class="normal">178</span>
<span class="normal">179</span>
<span class="normal">180</span>
<span class="normal">181</span>
<span class="normal">182</span>
<span class="normal">183</span>
<span class="normal">184</span>
<span class="normal">185</span>
<span class="normal">186</span>
<span class="normal">187</span>
<span class="normal">188</span>
<span class="normal">189</span>
<span class="normal">190</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">def</span> <span class="nf">generate_reward_function</span><span class="p">(</span>
    <span class="bp">self</span><span class="p">,</span> <span class="n">task_description</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span> <span class="n">iterations</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">1</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="n">List</span><span class="p">[</span><span class="n">State</span><span class="p">]:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Generate and iteratively improve a reward function using a Language Model (LLM).</span>

<span class="sd">    This method implements a sophisticated reward function generation process </span>
<span class="sd">    that involves multiple stages of creation, evaluation, and refinement.</span>

<span class="sd">    Key Stages:</span>
<span class="sd">        1. Initial Function Generation: Create two initial reward function candidates</span>
<span class="sd">        2. Evaluation: Compare and identify the best and worst performing functions</span>
<span class="sd">        3. Iterative Refinement: Progressively improve the worst-performing function</span>

<span class="sd">    Args:</span>
<span class="sd">        task_description (str): A detailed description of the task or environment </span>
<span class="sd">                                for which the reward function is being generated.</span>
<span class="sd">        iterations (int, optional): Number of refinement iterations to perform. </span>
<span class="sd">                                    Defaults to 1.</span>

<span class="sd">    Returns:</span>
<span class="sd">        List[State]: A list of generated and refined reward function states, </span>
<span class="sd">                    containing information about each function&#39;s performance </span>
<span class="sd">                    and implementation.</span>

<span class="sd">    Process Overview:</span>
<span class="sd">        - Generates two initial reward functions using an LLM</span>
<span class="sd">        - Evaluates these functions using a policy evaluation method</span>
<span class="sd">        - Selects the worst-performing function for refinement</span>
<span class="sd">        - Iteratively refines the function through self-refinement</span>
<span class="sd">        - Tracks the evolution of reward functions in the memory</span>

<span class="sd">    Detailed Workflow:</span>
<span class="sd">        1. Generate two initial reward functions</span>
<span class="sd">            - Uses a predefined prompt template</span>
<span class="sd">            - Applies configurable LLM generation options</span>
<span class="sd">            - Compiles and tests each generated function</span>
<span class="sd">        2. Evaluates initial functions</span>
<span class="sd">            - Identifies best and worst performing functions</span>
<span class="sd">        3. Iterative Refinement</span>
<span class="sd">            - Applies self-refinement to the worst-performing function</span>
<span class="sd">            - Re-evaluates after each refinement</span>
<span class="sd">            - Repeats for specified number of iterations</span>

<span class="sd">    Note:</span>
<span class="sd">        - Uses dynamic LLM configuration options</span>
<span class="sd">        - Supports flexible environment types</span>
<span class="sd">        - Provides a systematic approach to reward function generation</span>
<span class="sd">        - Logging at various stages for debugging and tracking</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="c1"># TODO Pourquoi additional_options ici et pas dans le constructeur ?</span>
    <span class="n">additional_options</span> <span class="o">=</span> <span class="p">{</span>
        <span class="s2">&quot;temperature&quot;</span><span class="p">:</span> <span class="mi">1</span><span class="p">,</span>
        <span class="c1"># &quot;num_predict&quot;: 3, # l&#39;impression que a change rien a creuser</span>
        <span class="c1"># &quot;mirostat&quot; : 1,</span>
        <span class="c1"># &quot;mirostat_eta&quot; : 0.01, #gre la vitesse de rponses du model (0.1 par dfaut) plus c&#39;est petit plus c&#39;est lent</span>
        <span class="c1"># &quot;mirostat_tau&quot; : 4.0, #gre la balance entre la diversit et la coherence des rponses (5.0 par dfaut) plus c&#39;est petit plus c&#39;est focus et cohrent</span>
        <span class="c1"># num_ctx&quot;: 2048, # nombre de tokens contextuels (2048 par dfaut peut tre pas ncessaire de changer)</span>
        <span class="c1"># repeat_last_n&quot;: 64, # combien le model regarde en arrire pour viter de rpter les rponses (64 par dfaut large pour nous)</span>
        <span class="c1"># &quot;repeat_penalty&quot;: 1.5, # pnalit pour viter de rpter les rponses (1.1 par dfaut au mac 1.5 intressant a modificer je pense)</span>
        <span class="c1"># &quot;stop&quot;: &quot;stop you here&quot; # pour stopper la gnration de texte pas intressant pour nous</span>
        <span class="c1"># &quot;tfs_z&quot;: 1.2, #reduire l&#39;impacte des token les moins &quot;pertinents&quot; (1.0 par dfaut pour dsactiver 2.0 max)</span>
        <span class="c1"># &quot;top_k&quot;: 30, #reduit la probabilit de gnrer des non-sens (40 par dfaut, 100 pour gnrer des rponses plus diverses, 10 pour des rponses plus &quot;conservatrices&quot;)</span>
        <span class="c1"># &quot;top_p&quot;: 0.95, #marche avec le top_k une forte valeur pour des texte plus diverses (0.9 par dfaut)</span>
        <span class="c1"># &quot;min_p&quot;: 0.05, #alternative au top_p, vise a s&#39;assurer de la balance entre qualit et diversit (0.0 par dfaut)</span>
        <span class="c1"># &quot;seed&quot;: 42, # a utiliser pour la reproductibilit des rsultats (important si publication)</span>
    <span class="p">}</span>
    <span class="c1">### INIT STAGE ###</span>
    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">]:</span>
        <span class="n">prompt</span> <span class="o">=</span> <span class="sa">f</span><span class="s2">&quot;&quot;&quot;</span>
<span class="s2">    Complete the reward function for a </span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">env_type</span><span class="o">.</span><span class="n">value</span><span class="si">}</span><span class="s2"> environment.</span>
<span class="s2">    Task Description: </span><span class="si">{</span><span class="n">task_description</span><span class="si">}</span><span class="s2"> Iteration </span><span class="si">{</span><span class="n">i</span><span class="o">+</span><span class="mi">1</span><span class="si">}</span><span class="s2">/</span><span class="si">{</span><span class="mi">2</span><span class="si">}</span>

<span class="s2">    complete this sentence:</span>
<span class="s2">    def reward_func(observations:np.ndarray, terminated: bool, truncated: bool) -&gt; float:</span>
<span class="s2">        </span><span class="se">\&quot;\&quot;\&quot;</span><span class="s2">Reward function for </span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">env_type</span><span class="o">.</span><span class="n">value</span><span class="si">}</span>

<span class="s2">        Args:</span>
<span class="s2">            observations (np.ndarray): observation on the current state</span>
<span class="s2">            terminated (bool): episode is terminated due a failure</span>
<span class="s2">            truncated (bool): episode is truncated due a success</span>

<span class="s2">        Returns:</span>
<span class="s2">            float: The reward for the current step</span>
<span class="s2">        </span><span class="se">\&quot;\&quot;\&quot;</span>
<span class="s2">    &quot;&quot;&quot;</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">llm</span><span class="o">.</span><span class="n">add_message</span><span class="p">(</span><span class="n">prompt</span><span class="p">)</span>
        <span class="n">response</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">llm</span><span class="o">.</span><span class="n">generate_response</span><span class="p">(</span>
            <span class="n">stream</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">additional_options</span><span class="o">=</span><span class="n">additional_options</span>
        <span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;additional options: </span><span class="si">{</span><span class="n">additional_options</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
        <span class="n">response</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">llm</span><span class="o">.</span><span class="n">print_Generator_and_return</span><span class="p">(</span><span class="n">response</span><span class="p">,</span> <span class="n">i</span><span class="p">)</span>
        <span class="n">reward_func</span><span class="p">,</span> <span class="n">response</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">get_runnable_function</span><span class="p">(</span><span class="n">response</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">memory</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">State</span><span class="p">(</span><span class="n">i</span><span class="p">,</span> <span class="n">reward_func</span><span class="p">,</span> <span class="n">response</span><span class="p">))</span>

    <span class="n">best_idx</span><span class="p">,</span> <span class="n">worst_idx</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">evaluate_policy</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">logger</span><span class="o">.</span><span class="n">debug</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;state to refine: </span><span class="si">{</span><span class="n">worst_idx</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
    <span class="c1">### SECOND STAGE ###</span>
    <span class="k">for</span> <span class="n">n</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">iterations</span> <span class="o">-</span> <span class="mi">1</span><span class="p">):</span>
        <span class="n">new_idx</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">self_refine_reward</span><span class="p">(</span><span class="n">worst_idx</span><span class="p">)</span>
        <span class="n">best_idx</span><span class="p">,</span> <span class="n">worst_idx</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">evaluate_policy</span><span class="p">(</span><span class="n">best_idx</span><span class="p">,</span> <span class="n">new_idx</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">logger</span><span class="o">.</span><span class="n">debug</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;state to refine: </span><span class="si">{</span><span class="n">worst_idx</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
    <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">memory</span>
</code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>

<div class="doc doc-object doc-function">


<h3 id="src.VIRAL.VIRAL.get_code" class="doc doc-heading">
            <code class="highlight language-python"><span class="n">get_code</span><span class="p">(</span><span class="n">response</span><span class="p">)</span></code>

</h3>


    <div class="doc doc-contents ">

        <p>Clean and validate a code response by removing code block markers and ensuring a function definition.</p>
<p>This method is designed to process code responses, typically extracted from text or code blocks,
by performing the following operations:</p>
<ol>
<li>Remove leading and trailing code block markers (```),</li>
<li>Remove the 'python' language identifier,</li>
<li>Strip any additional whitespace</li>
<li>Validate that the response contains a function definition</li>
</ol>


<p><span class="doc-section-title">Parameters:</span></p>
    <table>
      <thead>
        <tr>
          <th>Name</th>
          <th>Type</th>
          <th>Description</th>
          <th>Default</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td>
                <code>response</code>
            </td>
            <td>
                  <code>str</code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>The raw code response to be cleaned and validated.</p>
              </div>
            </td>
            <td>
                <em>required</em>
            </td>
          </tr>
      </tbody>
    </table>


    <p><span class="doc-section-title">Returns:</span></p>
    <table>
      <thead>
        <tr>
<th>Name</th>          <th>Type</th>
          <th>Description</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
<td><code>str</code></td>            <td>
                  <code>str</code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>The cleaned code response containing a function definition.</p>
              </div>
            </td>
          </tr>
      </tbody>
    </table>


<p><span class="doc-section-title">Raises:</span></p>
    <table>
      <thead>
        <tr>
          <th>Type</th>
          <th>Description</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td>
                  <code>ValueError</code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>If the response does not contain a valid function definition 
        (i.e., if "def " is not present in the cleaned response).</p>
              </div>
            </td>
          </tr>
      </tbody>
    </table>


<details class="logging" open>
  <summary>Logging</summary>
  <p>Logs the cleaned code at DEBUG level for debugging purposes.</p>
</details>
            <details class="quote">
              <summary>Source code in <code>src/VIRAL.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">192</span>
<span class="normal">193</span>
<span class="normal">194</span>
<span class="normal">195</span>
<span class="normal">196</span>
<span class="normal">197</span>
<span class="normal">198</span>
<span class="normal">199</span>
<span class="normal">200</span>
<span class="normal">201</span>
<span class="normal">202</span>
<span class="normal">203</span>
<span class="normal">204</span>
<span class="normal">205</span>
<span class="normal">206</span>
<span class="normal">207</span>
<span class="normal">208</span>
<span class="normal">209</span>
<span class="normal">210</span>
<span class="normal">211</span>
<span class="normal">212</span>
<span class="normal">213</span>
<span class="normal">214</span>
<span class="normal">215</span>
<span class="normal">216</span>
<span class="normal">217</span>
<span class="normal">218</span>
<span class="normal">219</span>
<span class="normal">220</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">def</span> <span class="nf">get_code</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">response</span><span class="p">:</span> <span class="nb">str</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">str</span><span class="p">:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Clean and validate a code response by removing code block markers and ensuring a function definition.</span>

<span class="sd">    This method is designed to process code responses, typically extracted from text or code blocks,</span>
<span class="sd">    by performing the following operations:\n</span>
<span class="sd">    1. Remove leading and trailing code block markers (```),</span>
<span class="sd">    2. Remove the &#39;python&#39; language identifier,</span>
<span class="sd">    3. Strip any additional whitespace</span>
<span class="sd">    4. Validate that the response contains a function definition</span>

<span class="sd">    Args:</span>
<span class="sd">        response (str): The raw code response to be cleaned and validated.</span>

<span class="sd">    Returns:</span>
<span class="sd">        str: The cleaned code response containing a function definition.</span>

<span class="sd">    Raises:</span>
<span class="sd">        ValueError: If the response does not contain a valid function definition </span>
<span class="sd">                    (i.e., if &quot;def &quot; is not present in the cleaned response).</span>

<span class="sd">    Logging:</span>
<span class="sd">        Logs the cleaned code at DEBUG level for debugging purposes.</span>
<span class="sd">&quot;&quot;&quot;</span>
    <span class="n">cleaned_response</span> <span class="o">=</span> <span class="n">response</span><span class="o">.</span><span class="n">strip</span><span class="p">(</span><span class="s2">&quot;```&quot;</span><span class="p">)</span><span class="o">.</span><span class="n">replace</span><span class="p">(</span><span class="s2">&quot;python&quot;</span><span class="p">,</span> <span class="s2">&quot;&quot;</span><span class="p">)</span><span class="o">.</span><span class="n">strip</span><span class="p">()</span>
    <span class="k">if</span> <span class="s2">&quot;def &quot;</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">cleaned_response</span><span class="p">:</span>
        <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;The answer does not contain a valid function definition.&quot;</span><span class="p">)</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">logger</span><span class="o">.</span><span class="n">debug</span><span class="p">(</span><span class="s2">&quot;Code nettoy pour compilation :</span><span class="se">\n</span><span class="s2">&quot;</span> <span class="o">+</span> <span class="n">cleaned_response</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">cleaned_response</span>
</code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>

<div class="doc doc-object doc-function">


<h3 id="src.VIRAL.VIRAL.get_runnable_function" class="doc doc-heading">
            <code class="highlight language-python"><span class="n">get_runnable_function</span><span class="p">(</span><span class="n">response</span><span class="p">,</span> <span class="n">error</span><span class="o">=</span><span class="kc">None</span><span class="p">)</span></code>

</h3>


    <div class="doc doc-contents ">

        <p>Process and validate a reward function for a gym environment.</p>
<p>This method attempts to generate and validate a reward function by:</p>
<ol>
<li>Handling potential previous errors</li>
<li>Creating a gym environment</li>
<li>Cleaning and compiling the code</li>
<li>Testing the reward function with a sample action</li>
<li>Recursively handling various potential errors</li>
</ol>


<p><span class="doc-section-title">Parameters:</span></p>
    <table>
      <thead>
        <tr>
          <th>Name</th>
          <th>Type</th>
          <th>Description</th>
          <th>Default</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td>
                <code>response</code>
            </td>
            <td>
                  <code>str</code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>The code response containing the reward function definition.</p>
              </div>
            </td>
            <td>
                <em>required</em>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>error</code>
            </td>
            <td>
                  <code>str</code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Previous error message to be added to LLM context. 
                    Defaults to None.</p>
              </div>
            </td>
            <td>
                  <code>None</code>
            </td>
          </tr>
      </tbody>
    </table>


    <p><span class="doc-section-title">Returns:</span></p>
    <table>
      <thead>
        <tr>
<th>Name</th>          <th>Type</th>
          <th>Description</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
<td><code>tuple</code></td>            <td>
                  <code><span title="typing.Callable">Callable</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>A tuple containing:
- Callable: The compiled and validated reward function
- str: The original response code</p>
              </div>
            </td>
          </tr>
      </tbody>
    </table>


<p><span class="doc-section-title">Raises:</span></p>
    <table>
      <thead>
        <tr>
          <th>Type</th>
          <th>Description</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td>
                  <code>-ValueError</code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Invalid function definition</p>
              </div>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                  <code>-SyntaxError</code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Syntax issues in the function</p>
              </div>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                  <code>-RuntimeError</code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Execution problems during function testing</p>
              </div>
            </td>
          </tr>
      </tbody>
    </table>


<details class="note" open>
  <summary>Note</summary>
  <ul>
<li>Uses recursion to handle potential errors</li>
<li>Relies on get_code, compile_reward_function, and test_reward_function methods</li>
<li>Provides a robust mechanism for generating valid reward functions</li>
</ul>
</details>
            <details class="quote">
              <summary>Source code in <code>src/VIRAL.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">222</span>
<span class="normal">223</span>
<span class="normal">224</span>
<span class="normal">225</span>
<span class="normal">226</span>
<span class="normal">227</span>
<span class="normal">228</span>
<span class="normal">229</span>
<span class="normal">230</span>
<span class="normal">231</span>
<span class="normal">232</span>
<span class="normal">233</span>
<span class="normal">234</span>
<span class="normal">235</span>
<span class="normal">236</span>
<span class="normal">237</span>
<span class="normal">238</span>
<span class="normal">239</span>
<span class="normal">240</span>
<span class="normal">241</span>
<span class="normal">242</span>
<span class="normal">243</span>
<span class="normal">244</span>
<span class="normal">245</span>
<span class="normal">246</span>
<span class="normal">247</span>
<span class="normal">248</span>
<span class="normal">249</span>
<span class="normal">250</span>
<span class="normal">251</span>
<span class="normal">252</span>
<span class="normal">253</span>
<span class="normal">254</span>
<span class="normal">255</span>
<span class="normal">256</span>
<span class="normal">257</span>
<span class="normal">258</span>
<span class="normal">259</span>
<span class="normal">260</span>
<span class="normal">261</span>
<span class="normal">262</span>
<span class="normal">263</span>
<span class="normal">264</span>
<span class="normal">265</span>
<span class="normal">266</span>
<span class="normal">267</span>
<span class="normal">268</span>
<span class="normal">269</span>
<span class="normal">270</span>
<span class="normal">271</span>
<span class="normal">272</span>
<span class="normal">273</span>
<span class="normal">274</span>
<span class="normal">275</span>
<span class="normal">276</span>
<span class="normal">277</span>
<span class="normal">278</span>
<span class="normal">279</span>
<span class="normal">280</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">def</span> <span class="nf">get_runnable_function</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">response</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span> <span class="n">error</span><span class="p">:</span> <span class="nb">str</span> <span class="o">=</span> <span class="kc">None</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Callable</span><span class="p">:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Process and validate a reward function for a gym environment.</span>

<span class="sd">    This method attempts to generate and validate a reward function by:\n</span>
<span class="sd">    1. Handling potential previous errors</span>
<span class="sd">    2. Creating a gym environment</span>
<span class="sd">    3. Cleaning and compiling the code</span>
<span class="sd">    4. Testing the reward function with a sample action</span>
<span class="sd">    5. Recursively handling various potential errors</span>

<span class="sd">    Args:</span>
<span class="sd">        response (str): The code response containing the reward function definition.</span>
<span class="sd">        error (str, optional): Previous error message to be added to LLM context. </span>
<span class="sd">                                Defaults to None.</span>

<span class="sd">    Returns:</span>
<span class="sd">        tuple: A tuple containing:</span>
<span class="sd">            - Callable: The compiled and validated reward function</span>
<span class="sd">            - str: The original response code</span>

<span class="sd">    Raises:</span>
<span class="sd">        - ValueError: Invalid function definition</span>
<span class="sd">        - SyntaxError: Syntax issues in the function</span>
<span class="sd">        - RuntimeError: Execution problems during function testing</span>

<span class="sd">    Note:</span>
<span class="sd">        - Uses recursion to handle potential errors</span>
<span class="sd">        - Relies on get_code, compile_reward_function, and test_reward_function methods</span>
<span class="sd">        - Provides a robust mechanism for generating valid reward functions</span>
<span class="sd">&quot;&quot;&quot;</span>
    <span class="k">if</span> <span class="n">error</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">llm</span><span class="o">.</span><span class="n">add_message</span><span class="p">(</span><span class="n">error</span><span class="p">)</span>
        <span class="n">response</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">llm</span><span class="o">.</span><span class="n">generate_response</span><span class="p">(</span><span class="n">stream</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
        <span class="n">response</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">llm</span><span class="o">.</span><span class="n">print_Generator_and_return</span><span class="p">(</span><span class="n">response</span><span class="p">)</span>
    <span class="k">try</span><span class="p">:</span>
        <span class="n">env</span> <span class="o">=</span> <span class="n">gym</span><span class="o">.</span><span class="n">make</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">env_type</span><span class="o">.</span><span class="n">value</span><span class="p">)</span>
        <span class="n">response</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">get_code</span><span class="p">(</span><span class="n">response</span><span class="p">)</span>
        <span class="n">reward_func</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">compile_reward_function</span><span class="p">(</span><span class="n">response</span><span class="p">)</span>
        <span class="n">state</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="n">env</span><span class="o">.</span><span class="n">reset</span><span class="p">()</span>
        <span class="n">action</span> <span class="o">=</span> <span class="n">env</span><span class="o">.</span><span class="n">action_space</span><span class="o">.</span><span class="n">sample</span><span class="p">()</span>
        <span class="n">next_observation</span><span class="p">,</span> <span class="n">_</span><span class="p">,</span> <span class="n">terminated</span><span class="p">,</span> <span class="n">truncated</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="n">env</span><span class="o">.</span><span class="n">step</span><span class="p">(</span><span class="n">action</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">test_reward_function</span><span class="p">(</span>
            <span class="n">reward_func</span><span class="p">,</span>
            <span class="n">observations</span><span class="o">=</span><span class="n">next_observation</span><span class="p">,</span>
            <span class="n">terminated</span><span class="o">=</span><span class="n">terminated</span><span class="p">,</span>
            <span class="n">truncated</span><span class="o">=</span><span class="n">truncated</span><span class="p">,</span>
        <span class="p">)</span>
    <span class="k">except</span> <span class="ne">ValueError</span> <span class="k">as</span> <span class="n">e</span><span class="p">:</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">logger</span><span class="o">.</span><span class="n">warning</span><span class="p">(</span><span class="nb">str</span><span class="p">(</span><span class="n">e</span><span class="p">))</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">get_runnable_function</span><span class="p">(</span><span class="n">response</span><span class="p">,</span> <span class="nb">str</span><span class="p">(</span><span class="n">e</span><span class="p">))</span>
    <span class="k">except</span> <span class="ne">SyntaxError</span> <span class="k">as</span> <span class="n">e</span><span class="p">:</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">logger</span><span class="o">.</span><span class="n">warning</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Error syntax </span><span class="si">{</span><span class="n">e</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">get_runnable_function</span><span class="p">(</span><span class="n">response</span><span class="p">,</span> <span class="nb">str</span><span class="p">(</span><span class="n">e</span><span class="p">))</span>
    <span class="k">except</span> <span class="ne">RuntimeError</span> <span class="k">as</span> <span class="n">e</span><span class="p">:</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">logger</span><span class="o">.</span><span class="n">warning</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Error execution </span><span class="si">{</span><span class="n">e</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">get_runnable_function</span><span class="p">(</span><span class="n">response</span><span class="p">,</span> <span class="nb">str</span><span class="p">(</span><span class="n">e</span><span class="p">))</span>

    <span class="k">return</span> <span class="n">reward_func</span><span class="p">,</span> <span class="n">response</span>
</code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>

<div class="doc doc-object doc-function">


<h3 id="src.VIRAL.VIRAL.self_refine_reward" class="doc doc-heading">
            <code class="highlight language-python"><span class="n">self_refine_reward</span><span class="p">(</span><span class="n">idx</span><span class="p">)</span></code>

</h3>


    <div class="doc doc-contents ">

        <p>Iteratively improve a reward function using self-refinement techniques.</p>
<p>This method implements an intelligent self-refinement process for reward functions
by leveraging a Language Model (LLM) to analyze and improve the current function
based on its previous performance.</p>


<details class="key-objectives" open>
  <summary>Key Objectives</summary>
  <ul>
<li>Analyze current reward function performance</li>
<li>Generate an improved version of the reward function</li>
<li>Maintain the core task objectives while optimizing the reward signal</li>
</ul>
</details>

<p><span class="doc-section-title">Parameters:</span></p>
    <table>
      <thead>
        <tr>
          <th>Name</th>
          <th>Type</th>
          <th>Description</th>
          <th>Default</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td>
                <code>idx</code>
            </td>
            <td>
                  <code>int</code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Index of the reward function in the memory to be refined.
    Typically the worst-performing function from previous evaluation.</p>
              </div>
            </td>
            <td>
                <em>required</em>
            </td>
          </tr>
      </tbody>
    </table>


    <p><span class="doc-section-title">Returns:</span></p>
    <table>
      <thead>
        <tr>
<th>Name</th>          <th>Type</th>
          <th>Description</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
<td><code>int</code></td>            <td>
                  <code><span title="typing.Callable">Callable</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Index of the newly created refined reward function in the memory.</p>
              </div>
            </td>
          </tr>
      </tbody>
    </table>


<details class="refinement-process" open>
  <summary>Refinement Process</summary>
  <ol>
<li>Construct a refinement prompt with:<ul>
<li>Current reward function code</li>
<li>Performance metrics</li>
<li>Explicit refinement goals</li>
</ul>
</li>
<li>Generate a new reward function using LLM</li>
<li>Compile and validate the new function</li>
<li>Append the new function to memory</li>
<li>Return the index of the new function</li>
</ol>
</details>

<details class="refinement-goals" open>
  <summary>Refinement Goals</summary>
  <ul>
<li>Increase success rate of the policy</li>
<li>Optimize the reward signal for better learning</li>
<li>Preserve the original task objectives</li>
<li>Improve overall performance</li>
</ul>
</details>

<details class="notes" open>
  <summary>Notes</summary>
  <ul>
<li>Uses the existing memory to track function evolution</li>
<li>Leverages LLM for intelligent function refinement</li>
<li>Provides a systematic approach to reward function improvement</li>
<li>Maintains a history of function iterations</li>
</ul>
</details>
            <details class="quote">
              <summary>Source code in <code>src/VIRAL.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">367</span>
<span class="normal">368</span>
<span class="normal">369</span>
<span class="normal">370</span>
<span class="normal">371</span>
<span class="normal">372</span>
<span class="normal">373</span>
<span class="normal">374</span>
<span class="normal">375</span>
<span class="normal">376</span>
<span class="normal">377</span>
<span class="normal">378</span>
<span class="normal">379</span>
<span class="normal">380</span>
<span class="normal">381</span>
<span class="normal">382</span>
<span class="normal">383</span>
<span class="normal">384</span>
<span class="normal">385</span>
<span class="normal">386</span>
<span class="normal">387</span>
<span class="normal">388</span>
<span class="normal">389</span>
<span class="normal">390</span>
<span class="normal">391</span>
<span class="normal">392</span>
<span class="normal">393</span>
<span class="normal">394</span>
<span class="normal">395</span>
<span class="normal">396</span>
<span class="normal">397</span>
<span class="normal">398</span>
<span class="normal">399</span>
<span class="normal">400</span>
<span class="normal">401</span>
<span class="normal">402</span>
<span class="normal">403</span>
<span class="normal">404</span>
<span class="normal">405</span>
<span class="normal">406</span>
<span class="normal">407</span>
<span class="normal">408</span>
<span class="normal">409</span>
<span class="normal">410</span>
<span class="normal">411</span>
<span class="normal">412</span>
<span class="normal">413</span>
<span class="normal">414</span>
<span class="normal">415</span>
<span class="normal">416</span>
<span class="normal">417</span>
<span class="normal">418</span>
<span class="normal">419</span>
<span class="normal">420</span>
<span class="normal">421</span>
<span class="normal">422</span>
<span class="normal">423</span>
<span class="normal">424</span>
<span class="normal">425</span>
<span class="normal">426</span>
<span class="normal">427</span>
<span class="normal">428</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">def</span> <span class="nf">self_refine_reward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">idx</span><span class="p">:</span> <span class="nb">int</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Callable</span><span class="p">:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Iteratively improve a reward function using self-refinement techniques.</span>

<span class="sd">    This method implements an intelligent self-refinement process for reward functions</span>
<span class="sd">    by leveraging a Language Model (LLM) to analyze and improve the current function</span>
<span class="sd">    based on its previous performance.</span>

<span class="sd">    Key Objectives: </span>
<span class="sd">        - Analyze current reward function performance</span>
<span class="sd">        - Generate an improved version of the reward function</span>
<span class="sd">        - Maintain the core task objectives while optimizing the reward signal</span>

<span class="sd">    Args:</span>
<span class="sd">        idx (int): Index of the reward function in the memory to be refined.</span>
<span class="sd">                Typically the worst-performing function from previous evaluation.</span>

<span class="sd">    Returns:</span>
<span class="sd">        int: Index of the newly created refined reward function in the memory.</span>

<span class="sd">    Refinement Process:</span>
<span class="sd">        1. Construct a refinement prompt with:</span>
<span class="sd">            - Current reward function code</span>
<span class="sd">            - Performance metrics</span>
<span class="sd">            - Explicit refinement goals</span>
<span class="sd">        2. Generate a new reward function using LLM</span>
<span class="sd">        3. Compile and validate the new function</span>
<span class="sd">        4. Append the new function to memory</span>
<span class="sd">        5. Return the index of the new function</span>

<span class="sd">    Refinement Goals:</span>
<span class="sd">        - Increase success rate of the policy</span>
<span class="sd">        - Optimize the reward signal for better learning</span>
<span class="sd">        - Preserve the original task objectives</span>
<span class="sd">        - Improve overall performance</span>

<span class="sd">    Notes:</span>
<span class="sd">        - Uses the existing memory to track function evolution</span>
<span class="sd">        - Leverages LLM for intelligent function refinement</span>
<span class="sd">        - Provides a systematic approach to reward function improvement</span>
<span class="sd">        - Maintains a history of function iterations</span>
<span class="sd">&quot;&quot;&quot;</span>
    <span class="n">refinement_prompt</span> <span class="o">=</span> <span class="sa">f</span><span class="s2">&quot;&quot;&quot;</span>
<span class="s2">    improve the reward function to:</span>
<span class="s2">    - Increase success rate</span>
<span class="s2">    - Optimize reward signal</span>
<span class="s2">    - Maintain task objectives</span>

<span class="s2">    your best reward function:</span>
<span class="s2">    </span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">memory</span><span class="p">[</span><span class="n">idx</span><span class="p">]</span><span class="o">.</span><span class="n">reward_func_str</span><span class="si">}</span>

<span class="s2">    performance:</span>
<span class="s2">    </span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">memory</span><span class="p">[</span><span class="n">idx</span><span class="p">]</span><span class="o">.</span><span class="n">performances</span><span class="si">}</span>
<span class="s2">    &quot;&quot;&quot;</span>

    <span class="bp">self</span><span class="o">.</span><span class="n">llm</span><span class="o">.</span><span class="n">add_message</span><span class="p">(</span><span class="n">refinement_prompt</span><span class="p">)</span>
    <span class="n">refined_response</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">llm</span><span class="o">.</span><span class="n">generate_response</span><span class="p">(</span><span class="n">stream</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
    <span class="n">refined_response</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">llm</span><span class="o">.</span><span class="n">print_Generator_and_return</span><span class="p">(</span><span class="n">refined_response</span><span class="p">)</span>
    <span class="n">reward_func</span><span class="p">,</span> <span class="n">refined_response</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">get_runnable_function</span><span class="p">(</span><span class="n">refined_response</span><span class="p">)</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">memory</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">State</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">memory</span><span class="p">),</span> <span class="n">reward_func</span><span class="p">,</span> <span class="n">refined_response</span><span class="p">))</span>

    <span class="k">return</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">memory</span><span class="p">)</span> <span class="o">-</span> <span class="mi">1</span>
</code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>

<div class="doc doc-object doc-function">


<h3 id="src.VIRAL.VIRAL.test_reward_function" class="doc doc-heading">
            <code class="highlight language-python"><span class="n">test_reward_function</span><span class="p">(</span><span class="n">reward_function</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span></code>

</h3>


    <div class="doc doc-contents ">

        <p>Test the compiled reward function with provided inputs to validate its execution.</p>
<p>This method serves as a crucial validation step in the reward function generation 
process. It attempts to execute the reward function with the given arguments and 
logs the output or raises an error if execution fails.</p>


<details class="purpose" open>
  <summary>Purpose</summary>
  <ul>
<li>Verify the reward function can be executed without errors</li>
<li>Log the reward function's output for debugging</li>
<li>Ensure the function returns a valid result in the context of a gym environment</li>
</ul>
</details>

<p><span class="doc-section-title">Parameters:</span></p>
    <table>
      <thead>
        <tr>
          <th>Name</th>
          <th>Type</th>
          <th>Description</th>
          <th>Default</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td>
                <code>reward_function</code>
            </td>
            <td>
                  <code><span title="typing.Callable">Callable</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>The compiled reward function to be tested.</p>
              </div>
            </td>
            <td>
                <em>required</em>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>*args</code>
            </td>
            <td>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Variable length argument list to pass to the reward function.
Typically includes observations, actions, or environment states.</p>
              </div>
            </td>
            <td>
                  <code>()</code>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>**kwargs</code>
            </td>
            <td>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Arbitrary keyword arguments to pass to the reward function.
May include additional context like 'terminated' or 'truncated' flags.</p>
              </div>
            </td>
            <td>
                  <code>{}</code>
            </td>
          </tr>
      </tbody>
    </table>


<p><span class="doc-section-title">Raises:</span></p>
    <table>
      <thead>
        <tr>
          <th>Type</th>
          <th>Description</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td>
                  <code>RuntimeError</code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>If the reward function fails to execute successfully.
This includes any exceptions that occur during function invocation.</p>
              </div>
            </td>
          </tr>
      </tbody>
    </table>


<details class="logging" open>
  <summary>Logging</summary>
  <ul>
<li>Logs the reward function's output at DEBUG level when successful</li>
<li>Provides detailed error information if execution fails</li>
</ul>
</details>

<details class="notes" open>
  <summary>Notes</summary>
  <ul>
<li>Designed to be flexible with varying function signatures</li>
<li>Critical for validating dynamically generated reward functions</li>
<li>Part of the reward function generation quality control process</li>
</ul>
</details>
            <details class="quote">
              <summary>Source code in <code>src/VIRAL.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">328</span>
<span class="normal">329</span>
<span class="normal">330</span>
<span class="normal">331</span>
<span class="normal">332</span>
<span class="normal">333</span>
<span class="normal">334</span>
<span class="normal">335</span>
<span class="normal">336</span>
<span class="normal">337</span>
<span class="normal">338</span>
<span class="normal">339</span>
<span class="normal">340</span>
<span class="normal">341</span>
<span class="normal">342</span>
<span class="normal">343</span>
<span class="normal">344</span>
<span class="normal">345</span>
<span class="normal">346</span>
<span class="normal">347</span>
<span class="normal">348</span>
<span class="normal">349</span>
<span class="normal">350</span>
<span class="normal">351</span>
<span class="normal">352</span>
<span class="normal">353</span>
<span class="normal">354</span>
<span class="normal">355</span>
<span class="normal">356</span>
<span class="normal">357</span>
<span class="normal">358</span>
<span class="normal">359</span>
<span class="normal">360</span>
<span class="normal">361</span>
<span class="normal">362</span>
<span class="normal">363</span>
<span class="normal">364</span>
<span class="normal">365</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">def</span> <span class="nf">test_reward_function</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">reward_function</span><span class="p">:</span> <span class="n">Callable</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Test the compiled reward function with provided inputs to validate its execution.</span>

<span class="sd">    This method serves as a crucial validation step in the reward function generation </span>
<span class="sd">    process. It attempts to execute the reward function with the given arguments and </span>
<span class="sd">    logs the output or raises an error if execution fails.</span>

<span class="sd">    Purpose:</span>
<span class="sd">        - Verify the reward function can be executed without errors</span>
<span class="sd">        - Log the reward function&#39;s output for debugging</span>
<span class="sd">        - Ensure the function returns a valid result in the context of a gym environment</span>

<span class="sd">    Args:</span>
<span class="sd">        reward_function (Callable): The compiled reward function to be tested.</span>
<span class="sd">        *args: Variable length argument list to pass to the reward function.</span>
<span class="sd">            Typically includes observations, actions, or environment states.</span>
<span class="sd">        **kwargs: Arbitrary keyword arguments to pass to the reward function.</span>
<span class="sd">            May include additional context like &#39;terminated&#39; or &#39;truncated&#39; flags.</span>

<span class="sd">    Raises:</span>
<span class="sd">        RuntimeError: If the reward function fails to execute successfully.</span>
<span class="sd">            This includes any exceptions that occur during function invocation.</span>

<span class="sd">    Logging:</span>
<span class="sd">        - Logs the reward function&#39;s output at DEBUG level when successful</span>
<span class="sd">        - Provides detailed error information if execution fails</span>

<span class="sd">    Notes:</span>
<span class="sd">        - Designed to be flexible with varying function signatures</span>
<span class="sd">        - Critical for validating dynamically generated reward functions</span>
<span class="sd">        - Part of the reward function generation quality control process</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">try</span><span class="p">:</span>
        <span class="n">reward</span> <span class="o">=</span> <span class="n">reward_function</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">logger</span><span class="o">.</span><span class="n">debug</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Reward function output: </span><span class="si">{</span><span class="n">reward</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
    <span class="k">except</span> <span class="ne">Exception</span> <span class="k">as</span> <span class="n">e</span><span class="p">:</span>
        <span class="k">raise</span> <span class="ne">RuntimeError</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Error during reward function execution: </span><span class="si">{</span><span class="n">e</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
</code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>



  </div>

    </div>

</div>




  </div>

    </div>

</div>












                
              </article>
            </div>
          
          
  <script>var tabs=__md_get("__tabs");if(Array.isArray(tabs))e:for(var set of document.querySelectorAll(".tabbed-set")){var labels=set.querySelector(".tabbed-labels");for(var tab of tabs)for(var label of labels.getElementsByTagName("label"))if(label.innerText.trim()===tab){var input=document.getElementById(label.htmlFor);input.checked=!0;continue e}}</script>

<script>var target=document.getElementById(location.hash.slice(1));target&&target.name&&(target.checked=target.name.startsWith("__tabbed_"))</script>
        </div>
        
      </main>
      
        <footer class="md-footer">
  
  <div class="md-footer-meta md-typeset">
    <div class="md-footer-meta__inner md-grid">
      <div class="md-copyright">
  
  
    Made with
    <a href="https://squidfunk.github.io/mkdocs-material/" target="_blank" rel="noopener">
      Material for MkDocs
    </a>
  
</div>
      
    </div>
  </div>
</footer>
      
    </div>
    <div class="md-dialog" data-md-component="dialog">
      <div class="md-dialog__inner md-typeset"></div>
    </div>
    
    
    <script id="__config" type="application/json">{"base": "../..", "features": ["navigation.tabs", "search.highlight", "search.suggest", "search.share", "content.code.copy", "content.code.prettify", "content.action.edit", "content.action.view", "content.code.annotate", "content.tabs.link", "navigation.sections"], "search": "../../assets/javascripts/workers/search.6ce7567c.min.js", "translations": {"clipboard.copied": "Copied to clipboard", "clipboard.copy": "Copy to clipboard", "search.result.more.one": "1 more on this page", "search.result.more.other": "# more on this page", "search.result.none": "No matching documents", "search.result.one": "1 matching document", "search.result.other": "# matching documents", "search.result.placeholder": "Type to start searching", "search.result.term.missing": "Missing", "select.version": "Select version"}}</script>
    
    
      <script src="../../assets/javascripts/bundle.88dd0f4e.min.js"></script>
      
    
  </body>
</html>